{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone 1: Advertising"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Business Context:** \n\nRetail company, \"Fashion Haven,\" operates multiple stores in different cities. The company invests in advertising campaigns to promote its latest collections through various media sources like TV, Newspaper, and Radio. They want to understand the impact of each media source on their sales revenue to optimize their advertising strategy and improve overall business performance.\n\nCurrently, Fashion Haven lacks an effective method to predict the sales revenue generated from their advertising efforts accurately. As a result, they struggle to allocate their advertising budget optimally across different media channels, leading to sub optimal returns on investment and inefficient resource allocation.\n\nTo address this business problem, Fashion Haven has collected historical data containing information on various advertising campaigns (TV, Newspaper, Radio) and their corresponding sales revenue across their different store locations. The goal is to build a robust predictive model that accurately estimates the sales revenue based on the media sources' advertising budgets, helping the company make data-driven decisions and drive business growth.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Description:\n",
        "\n",
        "The data contains the different attributes of the advertising business. The detailed data dictionary is given below.\n",
        "\n",
        "* TV: Expenditure on media resource- TV \n",
        "* Radio: Expenditure on media resource- Radio \n",
        "* NewsPaper: Expenditure on media resource- Newspaper \n",
        "* Sales: Target Column - Amount of Sales"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Connect to the Workspace **  "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credential = DefaultAzureCredential()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504381061
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"6793e723-756c-4c5d-84c0-812f1bb4c679\", # Subscription ID\n",
        "    resource_group_name=\"JuvlinResourceGroup\",              # Resource Group\n",
        "    workspace_name=\"JuvlinWorkspace\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504381404
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Upload the dataset on Blob Storage as Data Asset **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Data Asset created from File uploaded to Blob Storage\n",
        "data_asset = ml_client.data.get(\"advertising_data\", version=\"1\")\n",
        "da_path=data_asset.path\t\t\t\t\t\t\t\t\n",
        "print(da_path)\t\t"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azureml://subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace/datastores/workspaceblobstore/paths/UI/2024-11-09_202832_UTC/advertising_raw.csv/\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504382161
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Create a Compute Resource to run the Jobs **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Assign Name to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster-E2E\"\n",
        "\n",
        "# Define the Azure ML compute object with the intended parameters\n",
        "cpu_cluster = AmlCompute(\n",
        "    name=cpu_compute_target,\n",
        "    type=\"amlcompute\",                 # Azure ML Compute is the on-demand VM service\n",
        "    size=\"STANDARD_D2_V3\",             # VM Family\n",
        "    min_instances=0,                   # Minimum running nodes when there is no job running\n",
        "    max_instances=1,                   # Nodes in cluster\n",
        "    idle_time_before_scale_down=180,   # How many seconds will the node running after the job termination\n",
        "    tier=\"Dedicated\",                  # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        ")\n",
        "\n",
        "try:\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)  # Check if the compute target already exists\n",
        "    print(\n",
        "        f\"Compute Cluster {cpu_compute_target} exists, reuse it as is.\"\n",
        "    )\n",
        "except Exception:\n",
        "    print(\"Creating a new Compute Cluster...\") \n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster).result()   # Pass the object to MLClient's create_or_update method\n",
        "    print(\n",
        "    f\"AMLCompute Cluster {cpu_cluster.name} created, the compute size is {cpu_cluster.size}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Compute Cluster cpu-cluster-E2E exists, reuse it as is.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504382469
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Create a Custom Job Environment **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Name of the directory to create\n",
        "dependencies_dir = \"./env\"\n",
        "\n",
        "# Make directory, if exists don't raise an exception \n",
        "os.makedirs(dependencies_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504382686
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Create YAML File with required dependencies **\n",
        "\n",
        "-  ** 1. Create and Register the Custom Job Environment in the Workspace. **\n",
        "-  ** 2. The Environment will be packaged into a Docker Container at runtime. **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {dependencies_dir}/conda1.yaml\n",
        "\n",
        "name: sklearn-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - pip=21.2.4\n",
        "  - scikit-learn=1.0.2\n",
        "  - scipy=1.7.1\n",
        "  - pandas\n",
        "  - numpy\n",
        "  - pip:\n",
        "      - mlflow==2.8.1\n",
        "      - azureml-mlflow==1.51.0\n",
        "      - azureml-core==1.51.0  \n",
        "      - azureml-inference-server-http\n",
        "      - cloudpickle==1.6.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./env/conda1.yaml\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731214618379
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Create Environment for ML Tasks **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Environment Class from the azure.ai.ml.entities module\n",
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "\n",
        "# Name of the Custom Environment to create\n",
        "custom_env_name = \"Milestone1_Project_E2E\"\n",
        "\n",
        "# Create Environment object with the specified properties\n",
        "job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom Environment for ML task\",\n",
        "    conda_file=os.path.join(dependencies_dir, \"conda1.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "job_env = ml_client.environments.create_or_update(job_env)\n",
        "\n",
        "# Print information for registered environment\n",
        "print(\n",
        "    f\"Environment {job_env.name} registered to workspace, the environment version is {job_env.version}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment Milestone1_Project_E2E registered to workspace, the environment version is 9\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504384923
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Exploratory Data Analysis **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required Libraries\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "df = pd.read_csv(da_path)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504397902
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse Features to the correct datatypes\n",
        "df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 200 entries, 0 to 199\nData columns (total 4 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   TV         200 non-null    float64\n 1   Radio      200 non-null    float64\n 2   Newspaper  200 non-null    float64\n 3   Sales      200 non-null    float64\ndtypes: float64(4)\nmemory usage: 6.4 KB\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504398244
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Table Summary\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "               TV       Radio   Newspaper       Sales\ncount  200.000000  200.000000  200.000000  200.000000\nmean   147.042500   23.264000   30.554000   14.022500\nstd     85.854236   14.846809   21.778621    5.217457\nmin      0.700000    0.000000    0.300000    1.600000\n25%     74.375000    9.975000   12.750000   10.375000\n50%    149.750000   22.900000   25.750000   12.900000\n75%    218.825000   36.525000   45.100000   17.400000\nmax    296.400000   49.600000  114.000000   27.000000",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>Radio</th>\n      <th>Newspaper</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>200.000000</td>\n      <td>200.000000</td>\n      <td>200.000000</td>\n      <td>200.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>147.042500</td>\n      <td>23.264000</td>\n      <td>30.554000</td>\n      <td>14.022500</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>85.854236</td>\n      <td>14.846809</td>\n      <td>21.778621</td>\n      <td>5.217457</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.700000</td>\n      <td>0.000000</td>\n      <td>0.300000</td>\n      <td>1.600000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>74.375000</td>\n      <td>9.975000</td>\n      <td>12.750000</td>\n      <td>10.375000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>149.750000</td>\n      <td>22.900000</td>\n      <td>25.750000</td>\n      <td>12.900000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>218.825000</td>\n      <td>36.525000</td>\n      <td>45.100000</td>\n      <td>17.400000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>296.400000</td>\n      <td>49.600000</td>\n      <td>114.000000</td>\n      <td>27.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504398615
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 record\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "      TV  Radio  Newspaper  Sales\n0  230.1   37.8       69.2   22.1\n1   44.5   39.3       45.1   10.4\n2   17.2   45.9       69.3    9.3\n3  151.5   41.3       58.5   18.5\n4  180.8   10.8       58.4   12.9",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>Radio</th>\n      <th>Newspaper</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>230.1</td>\n      <td>37.8</td>\n      <td>69.2</td>\n      <td>22.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44.5</td>\n      <td>39.3</td>\n      <td>45.1</td>\n      <td>10.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17.2</td>\n      <td>45.9</td>\n      <td>69.3</td>\n      <td>9.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>151.5</td>\n      <td>41.3</td>\n      <td>58.5</td>\n      <td>18.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>180.8</td>\n      <td>10.8</td>\n      <td>58.4</td>\n      <td>12.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504398985
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the last 5 record\n",
        "df.tail()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "        TV  Radio  Newspaper  Sales\n195   38.2    3.7       13.8    7.6\n196   94.2    4.9        8.1    9.7\n197  177.0    9.3        6.4   12.8\n198  283.6   42.0       66.2   25.5\n199  232.1    8.6        8.7   13.4",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>Radio</th>\n      <th>Newspaper</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>195</th>\n      <td>38.2</td>\n      <td>3.7</td>\n      <td>13.8</td>\n      <td>7.6</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>94.2</td>\n      <td>4.9</td>\n      <td>8.1</td>\n      <td>9.7</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>177.0</td>\n      <td>9.3</td>\n      <td>6.4</td>\n      <td>12.8</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>283.6</td>\n      <td>42.0</td>\n      <td>66.2</td>\n      <td>25.5</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>232.1</td>\n      <td>8.6</td>\n      <td>8.7</td>\n      <td>13.4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504399398
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "df.isnull().sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "TV           0\nRadio        0\nNewspaper    0\nSales        0\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504399797
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Conclusion: There are no missing or null values **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for all duplicate rows\n",
        "df[df.duplicated()]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "Empty DataFrame\nColumns: [TV, Radio, Newspaper, Sales]\nIndex: []",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>Radio</th>\n      <th>Newspaper</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504400191
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Conclusion: There are no duplicate records **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA Conclusion: Data is clean and no additional preprocessing is needed ###"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Create a Training Script to perform the Training Job **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Directory to store Training Script file\n",
        "import os\n",
        "\n",
        "src_dir = \"./src\"\n",
        "os.makedirs(src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504400546
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/milestone1_training.py\n",
        "\n",
        "# Import required Libraries\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# Create an argument parser for input arguments from command line\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument('--criterion', type=str, default='mse', help='measure the quality of a split')\n",
        "    parser.add_argument('--max-depth', type=int, default=None, help='The maximum depth of the tree.')\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # Enable AutoLogging\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    # Print Input Arguments\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    # Load Input Data\n",
        "    print(\"input data:\", args.data)\n",
        "    df = pd.read_csv(args.data)\n",
        "\n",
        "    # Log input hyperparameters\n",
        "    mlflow.log_param('Criterion', str(args.criterion))\n",
        "    mlflow.log_param('Max depth', str(args.max_depth))\n",
        "\n",
        "    # Split data into features (X) and target (y)\n",
        "    X = df[['TV', 'Radio', 'Newspaper']]\n",
        "    y = df['Sales']\n",
        "    \n",
        "    # Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=args.test_train_ratio, random_state=42)\n",
        "    \n",
        "    # Initialize and Train a Decision Tree Regressor\n",
        "\n",
        "    tree_model = DecisionTreeRegressor(criterion=args.criterion, max_depth=args.max_depth, random_state=42)\n",
        "    tree_model = tree_model.fit(X_train, y_train)\n",
        "    tree_predictions = tree_model.predict(X_test)\n",
        "\n",
        "    # Compute and Log Model for MSE metric\n",
        "    mse = mean_squared_error(y_test, tree_predictions)\n",
        "    print(f\"Mean Squared Error on test set: {mse}\")\n",
        "    mlflow.log_metric('Mean Squared Error', float(mse))\n",
        "\n",
        "    # Set Name for the Registered Model\n",
        "    registered_model_name=\"milestone1_model\"\n",
        "\n",
        "    # Register Model to the Workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=tree_model,\n",
        "        registered_model_name=registered_model_name,\n",
        "        artifact_path=registered_model_name\n",
        "    )\n",
        "\n",
        "    # Save Model to a File\n",
        "    print(\"Saving the model via MLFlow\")\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=tree_model,\n",
        "        path=os.path.join(registered_model_name, 'trained_model'),\n",
        "    )\n",
        "   \n",
        "    # End MLflow tracking\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/milestone1_training.py\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731214681568
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Configure the Training Job **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required Modules\n",
        "\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "# Define a new AML job using the Command function\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",           \n",
        "            path=da_path,                      # Path to the input data file        \n",
        "        ),\n",
        "        test_train_ratio=0.3,                  # Ratio of the data to be used for testing\n",
        "        criterion=\"mse\",                       # Criterion used to measure the quality of a split\n",
        "        max_depth=2,                           # Maximum depth of the Decision Tree\n",
        "    ),\n",
        "    \n",
        "    code=\"./src/\",                             # Specify Directory containing the code to be run in the job\n",
        " \n",
        "    # Specify command to run in the job, including the input data and parameters as command line arguments\n",
        "    command=\"python milestone1_training.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --criterion ${{inputs.criterion}} --max-depth ${{inputs.max_depth}}\",\n",
        " \n",
        "    environment=\"Milestone1_Project_E2E@latest\",     # Specify environment or job\n",
        "    compute=\"cpu-cluster-E2E\",                       # Specify compute target for job\n",
        "    experiment_name=\"milestone1_train_prediction\",   # Specify experiment name for job \n",
        "    display_name=\"milestone1_prediction\",            # Specify display name for job\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504401143
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Run the Training Job **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new Job or update using ml_client.create_or_update\n",
        "training_job = ml_client.create_or_update(job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504401649
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wait for the job to complete by streaming logs\n",
        "ml_client.jobs.stream(training_job.name)\n",
        "\n",
        "# Proceed with the next steps after the job is complete\n",
        "print(\"Job has completed. Proceeding to the next step.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: gentle_giraffe_kwb8mw9cx7\nWeb View: https://ml.azure.com/runs/gentle_giraffe_kwb8mw9cx7?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\nExecution Summary\n=================\nRunId: gentle_giraffe_kwb8mw9cx7\nWeb View: https://ml.azure.com/runs/gentle_giraffe_kwb8mw9cx7?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\nJob has completed. Proceeding to the next step.\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504873005
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Define the parameter space for Hyperparameter Tuning **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.sweep import Choice\n",
        "\n",
        "# Reuse the command_job created \n",
        "job_for_sweep = job(\n",
        "    criterion=Choice(values=[\"mse\"]),\n",
        "    max_depth=Choice(values=[2, 3, 4, 5]),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504873516
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Configure the Sweep Job for Tuning **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ** compute ** - specifies the compute target where the sweep job will run.\n",
        "- ** sampling_algorithm ** - specifies the search algorithm to use for hyperparameter tuning.\n",
        "- ** primary_metric ** - specifies the metric to optimize during hyperparameter tuning.\n",
        "- ** goal ** - specifies whether to maximize or minimize the primary metric.\n",
        "- ** max_total_trials ** - specifies the maximum number of trials to run during hyperparameter tuning.\n",
        "- ** max_concurrent_trials ** - specifies the maximum number of trials to run concurrently during hyperparameter tuning."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Sweep Job\n",
        "sweep_job = job_for_sweep.sweep(\n",
        "    compute=\"cpu-cluster-E2E\",\n",
        "    sampling_algorithm=\"random\",\n",
        "    primary_metric=\"Mean Squared Error\",\n",
        "    goal=\"Minimize\",\n",
        "    max_total_trials=4,\n",
        "    max_concurrent_trials=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504873895
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Run the Sweep Job **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create or update the Sweep Job\n",
        "returned_sweep_job = ml_client.create_or_update(sweep_job) "
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731504875670
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stream the output and wait until the Job is finished\n",
        "ml_client.jobs.stream(returned_sweep_job.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: hungry_kitten_rqmnbzg23l\nWeb View: https://ml.azure.com/runs/hungry_kitten_rqmnbzg23l?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\nStreaming azureml-logs/hyperdrive.txt\n=====================================\n\n[2024-11-13T13:34:34.6656382Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-13T13:34:34.8704292Z][SCHEDULER][INFO]Scheduling job, id='hungry_kitten_rqmnbzg23l_0' \n[2024-11-13T13:34:35.4425132Z][SCHEDULER][INFO]Successfully scheduled a job. Id='hungry_kitten_rqmnbzg23l_0' \n[2024-11-13T13:36:06.5389786Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-13T13:36:06.7296989Z][SCHEDULER][INFO]Scheduling job, id='hungry_kitten_rqmnbzg23l_1' \n[2024-11-13T13:36:07.0042169Z][SCHEDULER][INFO]Successfully scheduled a job. Id='hungry_kitten_rqmnbzg23l_1' \n[2024-11-13T13:37:08.1603650Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-13T13:37:08.3699378Z][SCHEDULER][INFO]Scheduling job, id='hungry_kitten_rqmnbzg23l_2' \n[2024-11-13T13:37:08.6908755Z][SCHEDULER][INFO]Successfully scheduled a job. Id='hungry_kitten_rqmnbzg23l_2' \n[2024-11-13T13:38:09.9535493Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-13T13:38:10.1214801Z][SCHEDULER][INFO]Scheduling job, id='hungry_kitten_rqmnbzg23l_3' \n[2024-11-13T13:38:10.5084028Z][SCHEDULER][INFO]Successfully scheduled a job. Id='hungry_kitten_rqmnbzg23l_3' \n[2024-11-13T13:38:40.3271882Z][GENERATOR][DEBUG]Setting all jobs generated as True, reason : Max number of jobs reached \n[2024-11-13T13:39:36.2686047Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n\nExecution Summary\n=================\nRunId: hungry_kitten_rqmnbzg23l\nWeb View: https://ml.azure.com/runs/hungry_kitten_rqmnbzg23l?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731507125469
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Refresh the latest status of the Job after Streaming\n",
        "returned_sweep_job = ml_client.jobs.get(name=returned_sweep_job.name)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731507125875
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Extract the run that gave Best Modeling results **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the Best Model\n",
        "from azure.ai.ml.entities import Model\n",
        "\n",
        "if returned_sweep_job.status == \"Completed\":\n",
        "\n",
        "    # Get the run with the best result\n",
        "    best_run = returned_sweep_job.properties[\"best_child_run_id\"]\n",
        "\n",
        "    # Get the Model from that run\n",
        "    model = Model(\n",
        "        # Stores the Best Model as \"milestone1_best_model\"\n",
        "        path=\"azureml://jobs/{}/outputs/artifacts/paths/milestone1_model/\".format(\n",
        "            best_run\n",
        "        ),\n",
        "        name=\"milestone1_best_model\",\n",
        "        description=\"Model created from Advertising for Milestone1 Project\",\n",
        "        type=\"custom_model\",\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print(\n",
        "        \"Sweep job status: {}. Please wait until it completes\".format(\n",
        "            returned_sweep_job.status\n",
        "        )\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731507126217
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best Model: {model.name}\")\n",
        "print(f\"Best Model Path: {model.path}\")\n",
        "print(f\"Best Model Type: {model.type}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Best Model: milestone1_best_model\nBest Model Path: azureml://jobs/hungry_kitten_rqmnbzg23l_2/outputs/artifacts/paths/milestone1_model/\nBest Model Type: custom_model\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731507167859
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Register the Best Model **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the Best Model\n",
        "registered_model = ml_client.models.create_or_update(model=model)\n",
        "print(f\"Best Model: {registered_model.name}\")\n",
        "print(f\"Best Model Path: {registered_model.path}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Best Model: milestone1_best_model\nBest Model Path: azureml://subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.hungry_kitten_rqmnbzg23l_2/milestone1_model\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731507169643
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Configure an Endpoint **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required Libraries\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "from azure.ai.ml.constants import AssetTypes"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731507169773
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"milestone1_best_model\"\n",
        "\n",
        "model = Model(\n",
        "    name=model_name,\n",
        "    #The name of the MLflow model.\n",
        "    path=\"milestone1_best_model/milestone1_decisiontree_model\",\n",
        "    #Path to the root directory of the model.\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    #The type of the model asset(MLflow model).\n",
        "    description=\"MLflow model for the pima classification problem\",\n",
        "    #The purpose of the model.\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731507169904
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a unique Endpoint Name\n",
        "endpoint_suffix = \"juvlin\"\n",
        "endpoint_name = \"milestone1-endpoint-\" + endpoint_suffix\n",
        "print(f\"Endpoint name: {endpoint_name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint name: milestone1-endpoint-juvlin\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731507170049
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the Endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name,   # Unique Endpoint Name within Deployment\n",
        "    description=\"An online endpoint serving an MLflow model, for Milestone1 Advertising Prediction task\",\n",
        "                          # A string describing the purpose of the endpoint\n",
        "    auth_mode=\"key\",      # Authentication mode for endpoint - API key\n",
        "    tags={\"foo\": \"bar\"},  # Dictionary of key-value pairs to tag the Endpoint\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731507170189
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Create an Endpoint **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Endpoint\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://milestone1-endpoint-juvlin.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://milestone1-endpoint-juvlin.eastus2.inference.ml.azure.com/swagger.json', 'name': 'milestone1-endpoint-juvlin', 'description': 'An online endpoint serving an MLflow model, for Milestone1 Advertising Prediction task', 'tags': {'foo': 'bar'}, 'properties': {'createdBy': 'Juvlin Pinheiro', 'createdAt': '2024-11-13T14:12:50.919396+0000', 'lastModifiedAt': '2024-11-13T14:12:50.919396+0000', 'azureml.onlineendpointid': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/juvlinresourcegroup/providers/microsoft.machinelearningservices/workspaces/juvlinworkspace/onlineendpoints/milestone1-endpoint-juvlin', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oeidp:533a1434-a3da-4be8-bff0-922142657211:a8121253-93fd-4c12-98d6-cd8c24c8033c?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/onlineEndpoints/milestone1-endpoint-juvlin', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/pinhe512611/code/Users/pinhe51261/Code', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f81eed273a0>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f81f1679a50>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731507233867
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Create a Deployment Script to perform Model Deployment **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/deploymodel.py\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import json\n",
        "import mlflow\n",
        "from io import StringIO\n",
        "from mlflow.pyfunc.scoring_server import infer_and_parse_json_input\n",
        "\n",
        "# Application Insights Setup\n",
        "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
        "\n",
        "# Configure logging to Application Insights\n",
        "# app_insights_conn_str = 'InstrumentationKey=e040f1cb-4a7a-4009-87be-7861c813da51;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/'\n",
        "application_insights_connection_string= 'InstrumentationKey=e040f1cb-4a7a-4009-87be-7861c813da51;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/'\n",
        "handler = AzureLogHandler(connection_string=app_insights_conn_str)\n",
        "logger = logging.getLogger()\n",
        "logger.addHandler(handler)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    global input_schema\n",
        "\n",
        "    # Load the model from the Azure ML directory\n",
        "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"milestone1_decisiontree_model\")\n",
        "    model = mlflow.pyfunc.load_model(model_path)\n",
        "    input_schema = model.metadata.get_input_schema()\n",
        "\n",
        "def run(raw_data):\n",
        "    # Parse input JSON data\n",
        "    json_data = json.loads(raw_data)\n",
        "    if \"input_data\" not in json_data:\n",
        "        raise Exception(\"Request must contain a top level key named 'input_data'\")\n",
        "    \n",
        "    # Parse data according to input schema\n",
        "    serving_input = json_data[\"input_data\"]\n",
        "    data = infer_and_parse_json_input(json.dumps(serving_input), input_schema)\n",
        "\n",
        "    # Generate predictions\n",
        "    predictions = model.predict(data)\n",
        "\n",
        "    # Log data and predictions\n",
        "    logger.info(\"Data:{0},Predictions:{1}\".format(str(data),str(predictions)))\n",
        "\n",
        "    # Convert predictions to JSON and return\n",
        "    result = StringIO()\n",
        "    predictions_to_json(predictions, result)\n",
        "    return result.getvalue()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/deploymodel.py\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from azure.ai.ml.entities import CodeConfiguration, ManagedOnlineDeployment, OnlineRequestSettings\n",
        "\n",
        "# # Set up the request settings correctly using OnlineRequestSettings\n",
        "# request_settings = OnlineRequestSettings(\n",
        "#     request_timeout_ms=180000,  # 20 minutes in milliseconds\n",
        "#     max_concurrent_requests_per_instance=1,\n",
        "#     max_queue_wait_ms=600000  # 10 minutes in milliseconds\n",
        "# )\n",
        "# Create a new Deployment with name \"blue\"\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=endpoint_name,                  # Use the previously generated endpoint name\n",
        "    model=registered_model,                       # Use the registered model\n",
        "    environment=\"Milestone1_Project_E2E@latest\",  # Use the latest environment\"\n",
        "    # Use the code in the \"./src\" directory and the \"score.py\" script\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src\", scoring_script=\"deploymodel.py\"\n",
        "    ),\n",
        "    instance_type=\"Standard_E2s_v3\",              # Use a single instance of type \"Standard_E2s_v3\"\n",
        "    # instance_type=\"Standard_F4s_v2\",\n",
        "    # instance_type=\"Standard_D2s_v3\",\n",
        "    # instance_type=\"Standard_F2s_v2\",\n",
        "    instance_count=1,\n",
        "    app_insights_enabled=True,                    # Enable Application Insights for the deployment\n",
        "    # request_settings=request_settings,  # Pass the OnlineRequestSettings instance\n",
        "    # request_settings=request_settings,\n",
        "    # liveness_probe=liveness_probe_settings  # Add the liveness probe settings\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731508562407
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"Model Path: {model_path}\")\n",
        "# print(f\"Model Name: {model.name}\")"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731508562608
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy the Model to Endpoint\n",
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint milestone1-endpoint-juvlin exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".............................."
        },
        {
          "output_type": "error",
          "ename": "HttpResponseError",
          "evalue": "(ResourceNotReady) User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready\nCode: ResourceNotReady\nMessage: User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationFailed\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/base_polling.py:757\u001b[0m, in \u001b[0;36mLROBasePolling.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 757\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BadStatus \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/base_polling.py:789\u001b[0m, in \u001b[0;36mLROBasePolling._poll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _failed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus()):\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OperationFailed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation failed or canceled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    791\u001b[0m final_get_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation\u001b[38;5;241m.\u001b[39mget_final_get_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response)\n",
            "\u001b[0;31mOperationFailed\u001b[0m: Operation failed or canceled",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Deploy the Model to Endpoint\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monline_deployments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblue_deployment\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/_poller.py:251\u001b[0m, in \u001b[0;36mLROPoller.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PollingReturnType_co:\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m    the result available after the specified timeout.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_polling_method\u001b[38;5;241m.\u001b[39mresource()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:94\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/_poller.py:270\u001b[0m, in \u001b[0;36mLROPoller.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread\u001b[38;5;241m.\u001b[39mjoin(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# Was None\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/_poller.py:185\u001b[0m, in \u001b[0;36mLROPoller._start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start the long running operation.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03mOn completion, runs any callbacks.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_polling_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error\u001b[38;5;241m.\u001b[39mcontinuation_token:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/polling/base_polling.py:772\u001b[0m, in \u001b[0;36mLROBasePolling.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(\n\u001b[1;32m    766\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response,\n\u001b[1;32m    767\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(err),\n\u001b[1;32m    768\u001b[0m         error\u001b[38;5;241m=\u001b[39merr,\n\u001b[1;32m    769\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailed \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 772\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response, error\u001b[38;5;241m=\u001b[39merr) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
            "\u001b[0;31mHttpResponseError\u001b[0m: (ResourceNotReady) User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready\nCode: ResourceNotReady\nMessage: User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready"
          ]
        }
      ],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731508717750
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the endpoint and deployment names to verify they are correctly assigned\n",
        "print(\"Endpoint Name:\", endpoint_name)\n",
        "print(\"Deployment Name:\", \"blue\")\n",
        "# print(\"Endpoint invocation response:\", response)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731508717882
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect Logs for Specific Errors:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_deployments.get_logs(name=\"blue\", endpoint_name=endpoint_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731508717898
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Delete the Endpoint **\n",
        "\n",
        "**Important!** An Endpoint is a LIVE node which is always running, ready to process & predict to give you output. So unless you are making real-time predictions on streaming data, delete your endpoints after use"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete Endpoint\n",
        "# ml_client.online_endpoints.begin_delete(name=endpoint_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731508717912
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}