{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MLS: Week 5 -  Model Serving"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This Python notebook covers the usage of endpoints for obtaining inferences and also includes guidance on utilizing canary deployment techniques*\n",
        "\n",
        "*In the context of model deployment, canary deployment is a highly recommended method to upgrade an existing baseline model to a newer version. This involves directing a controlled portion of live traffic to the upgraded endpoint and performing A/B testing to determine if the new version performs better than the baseline on live data. The canary deployment process typically begins by diverting a small percentage of live traffic, ranging from 1% to 5%, to the upgraded version. If there are no errors, traffic is gradually increased, thus minimizing the risk of potential issues during the transition. This approach ensures a smooth and cautious transition to the new version while maintaining a high degree of safety.*"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The German credit dataset is a dataset commonly used in credit risk analysis*\n",
        "\n",
        "* Age: the age of the applicant in years\n",
        "* Credit amount: the amount of credit applied\n",
        "* Duration: the duration of the credit in months\n",
        "* Risk: the risk associated with the credit, with two possible values: \"0\" or \"1\" \n",
        "* Sex: the gender of the applicant, with two possible values: \"male\" or \"female\"\n",
        "* Job: the type of job of the applicant\n",
        "* Housing: the type of housing of the applicant, with three possible values: \"rent\", \"own\", or \"free\" \n",
        "* Purpose: the purpose of the credit"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to the workspace\n",
        "\n",
        "First, we'll need to connect to your Azure Machine Learning workspace. The Azure Machine Learning workspace is the top-level resource for the service. It provides you with a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
        "\n",
        "We're using DefaultAzureCredential to get access to the workspace. This credential should be capable of handling most Azure SDK authentication scenarios."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install azure-ai-ml"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731762748339
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credential = DefaultAzureCredential()"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731762748561
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, get a handle to the workspace by providing your Subscription ID, Resource Group name, and workspace name. To find these parameters:\n",
        "\n",
        "* Look in the upper-right corner of the Azure Machine Learning studio toolbar for your workspace name.\n",
        "* Select your workspace name to show your Resource Group and Subscription ID.\n",
        "* Copy the values for Resource Group and Subscription ID into the code."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Get a handle to the workspace\n",
        "# ml_client = MLClient(\n",
        "#     credential=credential,\n",
        "#     subscription_id=\"0d86e202-dfd4-4954-bdc4-ba82f5e270bd\", #Provide your subscription ID as shown in the above screenshot\n",
        "#     resource_group_name=\"GLMLPOs\", #Provide your Resource Group as shown in the above screenshot\n",
        "#     workspace_name=\"azureml\",\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731762748756
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"6793e723-756c-4c5d-84c0-812f1bb4c679\", #Provide your subscription ID as shown in the above screenshot\n",
        "    resource_group_name=\"JuvlinResourceGroup\", #Provide your Resource Group as shown in the above screenshot\n",
        "    workspace_name=\"JuvlinWorkspace\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731762748954
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a compute resource to run the job\n",
        "\n",
        "Azure Machine Learning needs a compute resource to run a job. This resource can be single or multi-node machines with Linux or Windows OS, or a specific compute fabric like Spark.\n",
        "\n",
        "We only need a basic cluster for this task; thus, we'll pick a Standard_D2_v3 model with 2 CPU cores and 7 GB RAM to create an Azure Machine Learning compute."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster-model-serving\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure ML compute object with the intended parameters\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        # Azure ML Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_D2_V3\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=1,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=180,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster).result()\n",
        "\n",
        "print(\n",
        "    f\"AMLCompute with name {cpu_cluster.name} is created, the compute size is {cpu_cluster.size}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You already have a cluster named cpu-cluster-model-serving, we'll reuse it as is.\nAMLCompute with name cpu-cluster-model-serving is created, the compute size is STANDARD_D2_V3\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731762749888
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a job environment\n",
        "\n",
        "To run an Azure Machine Learning job, you'll need an environment. It encapsulates the dependencies (such as software runtime and libraries) needed to run our machine learning training script on our compute resource. This environment is similar to a Python environment on our local machine.\n",
        "\n",
        "We'll create a custom environment for our jobs, using a Conda YAML file."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a custom environment\n",
        "\n",
        "To create your custom environment, we'll define your Conda dependencies in a YAML file. First, create a directory for storing the file. We've named the directory env."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "## Set the name of the directory we want to create\n",
        "dependencies_dir = \"./env\"\n",
        "\n",
        "# # The os.makedirs() function creates a directory\n",
        "# exist_ok=True means that the function will not raise an exception if the directory already exists\n",
        "os.makedirs(dependencies_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731762750029
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, create the file in the dependencies directory. In this example, we've named the file conda.yml."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {dependencies_dir}/conda.yaml\n",
        "name: sklearn-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - pip=21.2.4\n",
        "  - scikit-learn=0.23.2\n",
        "  - scipy=1.7.1\n",
        "  - pip:  \n",
        "    - mlflow==2.3\n",
        "    - azureml-mlflow==1.51.0\n",
        "    - azureml-inference-server-http\n",
        "    - azureml-core==1.49.0\n",
        "    - cloudpickle==1.6.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./env/conda.yaml\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specification contains some usual packages (such as numpy and pip) that you'll use in our job.\n",
        "\n",
        "Next, use the YAML file to create and register this custom environment in our workspace. The environment will be packaged into a Docker container at runtime."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Environment class from the azure.ai.ml.entities module\n",
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "\n",
        "# Set the name of the custom environment we want to create\n",
        "custom_env_name = \"machine_learning_model_serving\"\n",
        "\n",
        "# Create an Environment object with the specified properties\n",
        "job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for machine learning task\",\n",
        "    conda_file=os.path.join(dependencies_dir, \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "job_env = ml_client.environments.create_or_update(job_env)\n",
        "\n",
        "# Print out some information about the registered environment\n",
        "print(\n",
        "    f\"Environment with name {job_env.name} is registered to workspace, the environment version is {job_env.version}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment with name machine_learning_model_serving is registered to workspace, the environment version is 3\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731762751400
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure and submit your training job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To use the training script, first create a directory where you will store the file.\n",
        "import os\n",
        "\n",
        "src_dir = \"./src\"\n",
        "os.makedirs(src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731762751557
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next, create the script file in the source directory. Description of the script is as follows:**\n\n* The scripts defines a command-line interface for training a Decision Tree model and gradient boosting model on a given input dataset, logs the results to MLflow, saves the trained model as an MLflow artifact, and registers it with the model registry.\n\n\n* The script first imports necessary libraries for building and evaluating the Decision Tree model, as well as libraries for logging the model and its parameters and metrics to MLflow.\n\n\n* Next, the script defines a main() function that sets up the command-line interface using the argparse library. The function reads in the input dataset from a specified path, sets the model parameters based on user input, and trains the model using the training data. The script then evaluates the trained model on a holdout test set and logs the resulting accuracy and confusion matrix to MLflow.\n\n\n* Finally, the script registers the trained model with the MLflow model registry by logging it as an MLflow artifact and then saving it to disk using mlflow.sklearn.log_model() and mlflow.sklearn.save_model(), respectively. The registered model can be deployed and served using the MLflow model serving capabilities."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### First Model : Gradient Boosting Classifier"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/score-gb.py\n",
        "\n",
        "# importing necessary libraries\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# create an argument parser to take input arguments from command line\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\", default=\"default_model\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # enable autologging\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    # print input arguments\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    # load input data\n",
        "    print(\"input data:\", args.data)\n",
        "    df = pd.read_csv(args.data)\n",
        "\n",
        "    # split the data into training and testing sets\n",
        "    train_df, test_df = train_test_split(\n",
        "        df,\n",
        "        test_size=args.test_train_ratio,\n",
        "    )\n",
        "\n",
        "    # Define the preprocessing steps for the numerical and categorical data\n",
        "    numeric_features = ['Age', 'Credit amount', 'Duration']\n",
        "    numeric_transformer = StandardScaler()\n",
        "\n",
        "    categorical_features = ['Sex', 'JOB', 'HOUSING', 'Purpose']\n",
        "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "    # Combine the preprocessing steps into a single transformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "    # Fit the transformer on the training data and apply it to both the training and testing data\n",
        "    X_train = preprocessor.fit_transform(train_df)\n",
        "    X_test = preprocessor.transform(test_df)\n",
        "\n",
        "    # Extract the label column\n",
        "    y_train = train_df.pop(\"risk\")\n",
        "    y_test = test_df.pop(\"risk\")\n",
        "\n",
        "    # initialize and train a Gradient Boosting classifier\n",
        "    gb_model = GradientBoostingClassifier()\n",
        "    gb_model = gb_model.fit(X_train, y_train)\n",
        "    gb_predictions = gb_model.predict(X_test)\n",
        "\n",
        "    # compute and log model accuracy\n",
        "    accuracy = gb_model.score(X_test, y_test)\n",
        "    print('Accuracy of GradientBoosting classifier on test set: {:.2f}'.format(accuracy))\n",
        "    mlflow.log_metric('Accuracy', float(accuracy))\n",
        "\n",
        "    # creating a confusion matrix\n",
        "    cm = confusion_matrix(y_test, gb_predictions)\n",
        "    print(cm)\n",
        "\n",
        "    # set the name for the registered model\n",
        "    registered_model_name =\"GradientBoosting_GC\"\n",
        "\n",
        "    ##########################\n",
        "    #<save and register model>\n",
        "    ##########################\n",
        "\n",
        "    # Registering the model to the workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=gb_model,\n",
        "        registered_model_name=registered_model_name,\n",
        "        artifact_path=registered_model_name\n",
        "    )\n",
        "\n",
        "    # # Saving the model to a file\n",
        "    print(\"Saving the model via MLFlow\")\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=gb_model,\n",
        "        path=os.path.join(registered_model_name, \"trained_model\"),\n",
        "    )\n",
        "    ###########################\n",
        "    #</save and register model>\n",
        "    ###########################\n",
        "\n",
        "    # end MLflow tracking\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/score-gb.py\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configure the command\n",
        "\n",
        "We'll use the general purpose command to run the training script and perform your desired tasks. Create a Command object to specify the configuration details of your training job."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "# Define a new AML job using the `command` function\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"./data/german_credit.csv\" # The path to the input data file\n",
        "        ),\n",
        "        test_train_ratio=0.2, # The ratio of the data to be used for testing\n",
        "    ),\n",
        "    # Specify the directory containing the code to be run in the job\n",
        "    code=\"./src/\",\n",
        "    # Specify the command to be run in the job, including the input data and parameters as command line arguments\n",
        "    command='python score-gb.py --data \"${{inputs.data}}\" --test_train_ratio \"${{inputs.test_train_ratio}}\"',\n",
        "    # Specify the environment to be used for the job\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    # Specify the compute target to be used for the job\n",
        "    compute=\"cpu-cluster-model-serving\",\n",
        "    # Specify the name of the experiment for the job\n",
        "    experiment_name=\"german_credit_training_v4\",\n",
        "     # Specify the display name for the job\n",
        "    display_name=\"gb_prediction_v4\",\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731762751864
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ml_client.create_or_update will create a new job if it does not exist or update the existing job if it does\n",
        "training_job_GC = ml_client.create_or_update(job)"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731762842411
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wait for the job to complete by streaming logs\n",
        "ml_client.jobs.stream(training_job_GC.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: sincere_glass_3cytt4pzsp\nWeb View: https://ml.azure.com/runs/sincere_glass_3cytt4pzsp?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\nExecution Summary\n=================\nRunId: sincere_glass_3cytt4pzsp\nWeb View: https://ml.azure.com/runs/sincere_glass_3cytt4pzsp?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731763337753
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Second Model : Decision Tree Classifier"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/score-dt.py\n",
        "\n",
        "# importing necessary libraries\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# create an argument parser to take input arguments from command line\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # enable autologging\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    # print input arguments\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "     # load input data\n",
        "    print(\"input data:\", args.data)\n",
        "    df = pd.read_csv(args.data)\n",
        "\n",
        "    # split the data into training and testing sets\n",
        "    train_df, test_df = train_test_split(\n",
        "        df,\n",
        "        test_size=args.test_train_ratio,\n",
        "    )\n",
        "\n",
        "    # Define the preprocessing steps for the numerical and categorical data\n",
        "    numeric_features = ['Age', 'Credit amount', 'Duration']\n",
        "    numeric_transformer = StandardScaler()\n",
        "\n",
        "    categorical_features = ['Sex', 'JOB', 'HOUSING', 'Purpose']\n",
        "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "    # Combine the preprocessing steps into a single transformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "    # Fit the transformer on the training data and apply it to both the training and testing data\n",
        "    X_train = preprocessor.fit_transform(train_df)\n",
        "    X_test = preprocessor.transform(test_df)\n",
        "\n",
        "    # Extract the label column\n",
        "    y_train = train_df.pop(\"risk\")\n",
        "    y_test = test_df.pop(\"risk\")\n",
        "\n",
        "    # initialize and train a decision tree classifier\n",
        "    tree_model = DecisionTreeClassifier()\n",
        "    tree_model = tree_model.fit(X_train, y_train)\n",
        "    tree_predictions = tree_model.predict(X_test)\n",
        "\n",
        "    # compute and log model accuracy\n",
        "    accuracy = tree_model.score(X_test, y_test)\n",
        "    print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(accuracy))\n",
        "    mlflow.log_metric('Accuracy', float(accuracy))\n",
        "\n",
        "    # creating a confusion matrix\n",
        "    cm = confusion_matrix(y_test, tree_predictions)\n",
        "    print(cm)\n",
        "\n",
        "    # set the name for the registered model\n",
        "    registered_model_name=\"Decisiontree_GC\"\n",
        "\n",
        "    ##########################\n",
        "    #<save and register model>\n",
        "    ##########################\n",
        "\n",
        "    # Registering the model to the workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=tree_model,\n",
        "        registered_model_name=registered_model_name,\n",
        "        artifact_path=registered_model_name\n",
        "    )\n",
        "\n",
        "    # # Saving the model to a file\n",
        "    print(\"Saving the model via MLFlow\")\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=tree_model,\n",
        "        path=os.path.join(registered_model_name, \"trained_model\"),\n",
        "    )\n",
        "    ###########################\n",
        "    #</save and register model>\n",
        "    ###########################\n",
        "   \n",
        "    # end MLflow tracking\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/score-dt.py\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configure the command\n",
        "\n",
        "We'll use the general purpose command to run the training script and perform your desired tasks. Create a Command object to specify the configuration details of your training job."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "# Define a new AML job using the `command` function\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"./data/german_credit.csv\" # The path to the input data file\n",
        "        ),\n",
        "        test_train_ratio=0.2, # The ratio of the data to be used for testing\n",
        "    ),\n",
        "    # Specify the directory containing the code to be run in the job\n",
        "    code=\"./src/\",\n",
        "    # Specify the command to be run in the job, including the input data and parameters as command line arguments\n",
        "    command='python score-dt.py --data \"${{inputs.data}}\" --test_train_ratio \"${{inputs.test_train_ratio}}\"',\n",
        "    # Specify the environment to be used for the job\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    # Specify the compute target to be used for the job\n",
        "    compute=\"cpu-cluster-model-serving\",\n",
        "    # Specify the name of the experiment for the job\n",
        "    experiment_name=\"german_credit_training_v4\",\n",
        "     # Specify the display name for the job\n",
        "    display_name=\"dt_prediction_v4\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731763492513
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ml_client.create_or_update will create a new job if it does not exist or update the existing job if it does\n",
        "training_job_DT = ml_client.create_or_update(job)"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731763501630
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wait for the job to complete by streaming logs\n",
        "ml_client.jobs.stream(training_job_DT.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: yellow_wheel_t0hnwqxfvx\nWeb View: https://ml.azure.com/runs/yellow_wheel_t0hnwqxfvx?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\nExecution Summary\n=================\nRunId: yellow_wheel_t0hnwqxfvx\nWeb View: https://ml.azure.com/runs/yellow_wheel_t0hnwqxfvx?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731763558272
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Endpoint Creation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a managed endpoint to receive requests. With the abstractions provided by Azure ML we can attach multiple models to this end point. Depending on the performance of the model variants behind the endpoint, we could shift traffic dynamically.  "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the required modules\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "from azure.identity import InteractiveBrowserCredential\n",
        "\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    CodeConfiguration\n",
        ")\n",
        "from azure.ai.ml.constants import AssetTypes"
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731764639367
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "online_endpoint_name = \"german-credit-classifier-juvlin\""
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765413590
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name, # Name of the endpoint\n",
        "    description=\"Model to predict german credit\", # Description of the endpoint\n",
        "    auth_mode=\"aml_token\" # Authentication mode for the endpoint\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765414757
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `MLClient` created earlier, we will now create the Endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://german-credit-classifier-juvlin.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://german-credit-classifier-juvlin.eastus2.inference.ml.azure.com/swagger.json', 'name': 'german-credit-classifier-juvlin', 'description': 'Model to predict german credit', 'tags': {}, 'properties': {'createdBy': 'Juvlin Pinheiro', 'createdAt': '2024-11-16T13:56:52.758303+0000', 'lastModifiedAt': '2024-11-16T13:56:52.758303+0000', 'azureml.onlineendpointid': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/juvlinresourcegroup/providers/microsoft.machinelearningservices/workspaces/juvlinworkspace/onlineendpoints/german-credit-classifier-juvlin', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oeidp:533a1434-a3da-4be8-bff0-922142657211:ce73fe06-337f-4212-ba32-f55da8ac7972?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/onlineEndpoints/german-credit-classifier-juvlin', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/pinhe512611/code/Users/pinhe51261/Code', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f7ca84d4b20>, 'auth_mode': 'aml_token', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f7ca84d4970>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765479771
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Registering Models"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting Model**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registered_model_GB= ml_client.models.get(\n",
        "    name=\"GradientBoosting_GC\",\n",
        "    version=2\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765502804
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registered_model_GB"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 53,
          "data": {
            "text/plain": "Model({'job_name': 'sincere_glass_3cytt4pzsp', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'GradientBoosting_GC', 'description': None, 'tags': {}, 'properties': {'flavors.python_function': '{\\n  \"model_path\": \"model.pkl\",\\n  \"predict_fn\": \"predict\",\\n  \"loader_module\": \"mlflow.sklearn\",\\n  \"python_version\": \"3.7.16\",\\n  \"env\": \"conda.yaml\"\\n}', 'flavors.sklearn': '{\\n  \"pickled_model\": \"model.pkl\",\\n  \"sklearn_version\": \"0.24.1\",\\n  \"serialization_format\": \"cloudpickle\",\\n  \"code\": null\\n}', 'flavors': 'python_function,sklearn', 'azureml.artifactPrefix': 'ExperimentRun/dcid.sincere_glass_3cytt4pzsp/GradientBoosting_GC', 'model_json': '{\"run_id\": \"sincere_glass_3cytt4pzsp\", \"artifact_path\": \"GradientBoosting_GC\", \"utc_time_created\": \"2024-11-16 13:21:08.304063\", \"flavors\": {\"python_function\": {\"model_path\": \"model.pkl\", \"predict_fn\": \"predict\", \"loader_module\": \"mlflow.sklearn\", \"python_version\": \"3.7.16\", \"env\": \"conda.yaml\"}, \"sklearn\": {\"pickled_model\": \"model.pkl\", \"sklearn_version\": \"0.24.1\", \"serialization_format\": \"cloudpickle\", \"code\": null}}, \"model_uuid\": \"167dafca5a78405ba732499611c105b5\", \"mlflow_version\": \"1.30.1\"}', 'azureml.storagePath': 'ExperimentRun/dcid.sincere_glass_3cytt4pzsp/GradientBoosting_GC', 'mlflow.modelSourceUri': 'azureml://experiments/german_credit_training_v4/runs/sincere_glass_3cytt4pzsp/artifacts/GradientBoosting_GC'}, 'print_as_yaml': False, 'id': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/models/GradientBoosting_GC/versions/2', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/pinhe512611/code/Users/pinhe51261/Code', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f7ca8a5e440>, 'serialize': <msrest.serialization.Serializer object at 0x7f7ca8a5d3f0>, 'version': '2', 'latest_version': None, 'path': 'azureml://subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.sincere_glass_3cytt4pzsp/GradientBoosting_GC', 'datastore': None, 'utc_time_created': None, 'flavors': {'python_function': {'model_path': 'model.pkl', 'predict_fn': 'predict', 'loader_module': 'mlflow.sklearn', 'python_version': '3.7.16', 'env': 'conda.yaml'}, 'sklearn': {'pickled_model': 'model.pkl', 'sklearn_version': '0.24.1', 'serialization_format': 'cloudpickle', 'code': ''}}, 'arm_type': 'model_version', 'type': 'mlflow_model', 'stage': 'Development'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765505364
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree model**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registered_model_DT = ml_client.models.get(\n",
        "    name=\"Decisiontree_GC\",\n",
        "    version=2\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765510340
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registered_model_DT"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 55,
          "data": {
            "text/plain": "Model({'job_name': 'yellow_wheel_t0hnwqxfvx', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'Decisiontree_GC', 'description': None, 'tags': {}, 'properties': {'flavors.python_function': '{\\n  \"model_path\": \"model.pkl\",\\n  \"predict_fn\": \"predict\",\\n  \"loader_module\": \"mlflow.sklearn\",\\n  \"python_version\": \"3.7.16\",\\n  \"env\": \"conda.yaml\"\\n}', 'flavors.sklearn': '{\\n  \"pickled_model\": \"model.pkl\",\\n  \"sklearn_version\": \"0.24.1\",\\n  \"serialization_format\": \"cloudpickle\",\\n  \"code\": null\\n}', 'flavors': 'python_function,sklearn', 'azureml.artifactPrefix': 'ExperimentRun/dcid.yellow_wheel_t0hnwqxfvx/Decisiontree_GC', 'model_json': '{\"run_id\": \"yellow_wheel_t0hnwqxfvx\", \"artifact_path\": \"Decisiontree_GC\", \"utc_time_created\": \"2024-11-16 13:25:37.866493\", \"flavors\": {\"python_function\": {\"model_path\": \"model.pkl\", \"predict_fn\": \"predict\", \"loader_module\": \"mlflow.sklearn\", \"python_version\": \"3.7.16\", \"env\": \"conda.yaml\"}, \"sklearn\": {\"pickled_model\": \"model.pkl\", \"sklearn_version\": \"0.24.1\", \"serialization_format\": \"cloudpickle\", \"code\": null}}, \"model_uuid\": \"87c7c084d0c449fb9a095010ac62f66c\", \"mlflow_version\": \"1.30.1\"}', 'azureml.storagePath': 'ExperimentRun/dcid.yellow_wheel_t0hnwqxfvx/Decisiontree_GC', 'mlflow.modelSourceUri': 'azureml://experiments/german_credit_training_v4/runs/yellow_wheel_t0hnwqxfvx/artifacts/Decisiontree_GC'}, 'print_as_yaml': False, 'id': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/models/Decisiontree_GC/versions/2', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/pinhe512611/code/Users/pinhe51261/Code', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f7ca8a5c580>, 'serialize': <msrest.serialization.Serializer object at 0x7f7ca8a5d6f0>, 'version': '2', 'latest_version': None, 'path': 'azureml://subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.yellow_wheel_t0hnwqxfvx/Decisiontree_GC', 'datastore': None, 'utc_time_created': None, 'flavors': {'python_function': {'model_path': 'model.pkl', 'predict_fn': 'predict', 'loader_module': 'mlflow.sklearn', 'python_version': '3.7.16', 'env': 'conda.yaml'}, 'sklearn': {'pickled_model': 'model.pkl', 'sklearn_version': '0.24.1', 'serialization_format': 'cloudpickle', 'code': ''}}, 'arm_type': 'model_version', 'type': 'mlflow_model', 'stage': 'Development'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 55,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765515116
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deployment Scripts"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The script is split into two main functions:**\n\n* **init()**: This function is responsible for loading the trained ML model. It uses the mlflow library to load the model from the AZUREML_MODEL_DIR environment variable. The input_schema variable is also set in this function by extracting it from the model metadata.\n\n\n* **run(raw_data)**: This function accepts raw data in JSON format, parses the input data from the request, and scores the data using the loaded ML model. The input data is extracted from the json_data object and transformed into the expected input format for the model using infer_and_parse_json_input function from mlflow.pyfunc.scoring_server module. The model's predict() function is then called to generate predictions. The input data and the predictions are logged using the logger.info() function, with the logger object being initialized in the code's beginning. Finally, the predictions are converted to JSON format using the predictions_to_json() function from mlflow.pyfunc.scoring_server module and returned as a string.\n\nThe code also initializes a logger object to log messages to Azure Application Insights using the AzureLogHandler from the opencensus.ext.azure.log_exporter library. The connection string to the Application Insights instance is provided in the application_insights_connection_string variable.\n\nOverall, the code performs the necessary steps to load a trained ML model and score data using that model, while also logging relevant information to Azure Application Insights."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision tree Script:**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile {src_dir}/dt_script.py\n",
        "\n",
        "# # Import necessary libraries and modules\n",
        "# import logging\n",
        "# import os\n",
        "# import json\n",
        "# import mlflow\n",
        "# from io import StringIO\n",
        "# from mlflow.pyfunc.scoring_server import infer_and_parse_json_input, predictions_to_json\n",
        "\n",
        "# ######################LOGGER#####################\n",
        "# # Set up Azure logging\n",
        "# import logging\n",
        "# from logging import Logger\n",
        "# from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
        "\n",
        "# # Connect to Application Insights and set logging level to INFO\n",
        "# application_insights_connection_string= 'InstrumentationKey=85de5fe8-9310-4e68-bb70-7ae940017984;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/;ApplicationId=7b4604c7-4039-4c00-b7a1-bd2e4c5a61a0'\n",
        "# handler = AzureLogHandler(\n",
        "# connection_string=application_insights_connection_string)\n",
        "# logger = logging.getLogger()\n",
        "# logger.addHandler(handler)\n",
        "# logger.setLevel(logging.INFO)\n",
        "\n",
        "# ####################################################\n",
        "\n",
        "# # Define the init() function to load the MLflow model\n",
        "# def init():\n",
        "#     global model\n",
        "#     global input_schema\n",
        "#     # \"model\" is the path of the mlflow artifacts when the model was registered. For automl\n",
        "#     # models, this is generally \"mlflow-model\".\n",
        "#     model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"Decisiontree_GC\")\n",
        "#     model = mlflow.pyfunc.load_model(model_path)\n",
        "#     input_schema = model.metadata.get_input_schema()\n",
        "\n",
        "# # Define the run() function to make predictions using the loaded model\n",
        "# # def run(raw_data):\n",
        "# #     # Parse input data\n",
        "# #     json_data = json.loads(raw_data)\n",
        "# #     if \"input_data\" not in json_data.keys():\n",
        "# #         raise Exception(\"Request must contain a top level key named 'input_data'\")\n",
        "# #     serving_input = json_data[\"input_data\"]\n",
        "# #     data = infer_and_parse_json_input(json.dumps(serving_input), input_schema)\n",
        "\n",
        "# #     # Make predictions\n",
        "# #     predictions = model.predict(data)\n",
        "\n",
        "# #     # Log the input data and predictions to Azure\n",
        "# #     logger.info(\"Data:{0},Predictions:{1}\".format(str(data),str(predictions)))\n",
        "\n",
        "# #     # Convert predictions to JSON format and return\n",
        "# #     result = StringIO()\n",
        "# #     predictions_to_json(predictions, result)\n",
        "# #     return result.getvalue()\n",
        "\n",
        "\n",
        "# # Define the run() function to make predictions using the loaded model\n",
        "# def run(raw_data):\n",
        "#     # Parse input data\n",
        "#     json_data = json.loads(raw_data)\n",
        "#     if \"input_data\" not in json_data.keys():\n",
        "#         raise Exception(\"Request must contain a top level key named 'input_data'\")\n",
        "#     serving_input = json.dumps(json_data[\"input_data\"])\n",
        "#     data = infer_and_parse_json_input(serving_input, input_schema)\n",
        "\n",
        "#     # Make predictions\n",
        "#     predictions = model.predict(data)\n",
        "\n",
        "#     # Log the input data and predictions to Azure\n",
        "#     logger.info(\"Data:{0},Predictions:{1}\".format(str(data),str(predictions)))\n",
        "\n",
        "#     # Convert predictions to JSON format and return\n",
        "#     result = StringIO()\n",
        "#     predictions_to_json(predictions, result)\n",
        "#     return result.getvalue()"
      ],
      "outputs": [],
      "execution_count": 56,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765526396
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/dt_script.py\n",
        "# Import necessary libraries and modules\n",
        "import logging\n",
        "import os\n",
        "import json\n",
        "import mlflow\n",
        "from io import StringIO\n",
        "from mlflow.pyfunc.scoring_server import infer_and_parse_json_input, predictions_to_json\n",
        "\n",
        "# Set up Azure logging\n",
        "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
        "\n",
        "# Connect to Application Insights and set logging level to INFO\n",
        "application_insights_connection_string = 'InstrumentationKey=85de5fe8-9310-4e68-bb70-7ae940017984;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/;ApplicationId=7b4604c7-4039-4c00-b7a1-bd2e4c5a61a0'\n",
        "handler = AzureLogHandler(connection_string=application_insights_connection_string)\n",
        "logger = logging.getLogger()\n",
        "logger.addHandler(handler)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Define the init() function to load the MLflow model\n",
        "def init():\n",
        "    global model\n",
        "    global input_schema\n",
        "    # \"model\" is the path of the mlflow artifacts when the model was registered. For automl\n",
        "    # models, this is generally \"mlflow-model\".\n",
        "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"Decisiontree_GC\")\n",
        "    model = mlflow.pyfunc.load_model(model_path)\n",
        "    input_schema = model.metadata.get_input_schema()\n",
        "\n",
        "# Define the run() function to make predictions using the loaded model\n",
        "def run(raw_data):\n",
        "    # Parse input data\n",
        "    json_data = json.loads(raw_data)\n",
        "    if \"input_data\" not in json_data.keys():\n",
        "        raise Exception(\"Request must contain a top level key named 'input_data'\")\n",
        "    \n",
        "    serving_input = json_data[\"input_data\"]\n",
        "    serving_input_str = json.dumps(serving_input)  # Convert the dictionary to a JSON string\n",
        "    data = infer_and_parse_json_input(serving_input_str, input_schema)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(data)\n",
        "\n",
        "    # Log the input data and predictions to Azure\n",
        "    logger.info(\"Data: {0}, Predictions: {1}\".format(str(data), str(predictions)))\n",
        "\n",
        "    # Convert predictions to JSON format and return\n",
        "    result = StringIO()\n",
        "    predictions_to_json(predictions, result)\n",
        "    return result.getvalue()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/dt_script.py\n"
        }
      ],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting :**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile {src_dir}/gb_script.py\n",
        "\n",
        "# # Import necessary libraries and modules\n",
        "# import logging\n",
        "# import os\n",
        "# import json\n",
        "# import mlflow\n",
        "# from io import StringIO\n",
        "# from mlflow.pyfunc.scoring_server import infer_and_parse_json_input, predictions_to_json\n",
        "\n",
        "# ######################LOGGER#####################\n",
        "# # Set up Azure logging\n",
        "# import logging\n",
        "# from logging import Logger\n",
        "# from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
        "\n",
        "# # Connect to Application Insights and set logging level to INFO\n",
        "# application_insights_connection_string= 'InstrumentationKey=85de5fe8-9310-4e68-bb70-7ae940017984;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/;ApplicationId=7b4604c7-4039-4c00-b7a1-bd2e4c5a61a0'\n",
        "# handler = AzureLogHandler(\n",
        "# connection_string=application_insights_connection_string)\n",
        "# logger = logging.getLogger()\n",
        "# logger.addHandler(handler)\n",
        "# logger.setLevel(logging.INFO)\n",
        "\n",
        "# ####################################################\n",
        "\n",
        "# # Define the init() function to load the MLflow model\n",
        "# def init():\n",
        "#     global model\n",
        "#     global input_schema\n",
        "#     # \"model\" is the path of the mlflow artifacts when the model was registered. For automl\n",
        "#     # models, this is generally \"mlflow-model\".\n",
        "#     model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"GradientBoosting_GC\")\n",
        "#     model = mlflow.pyfunc.load_model(model_path)\n",
        "#     input_schema = model.metadata.get_input_schema()\n",
        "\n",
        "# # Define the run() function to make predictions using the loaded model\n",
        "# def run(raw_data):\n",
        "#     # Parse input data\n",
        "#     json_data = json.loads(raw_data)\n",
        "#     if \"input_data\" not in json_data.keys():\n",
        "#         raise Exception(\"Request must contain a top level key named 'input_data'\")\n",
        "#     serving_input = json.dumps(json_data[\"input_data\"])\n",
        "#     data = infer_and_parse_json_input(serving_input, input_schema)\n",
        "\n",
        "#     # Make predictions\n",
        "#     predictions = model.predict(data)\n",
        "\n",
        "#     # Log the input data and predictions to Azure\n",
        "#     logger.info(\"Data:{0},Predictions:{1}\".format(str(data),str(predictions)))\n",
        "\n",
        "#     # Convert predictions to JSON format and return\n",
        "#     result = StringIO()\n",
        "#     predictions_to_json(predictions, result)\n",
        "#     return result.getvalue()\n"
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765543153
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/gb_script.py\n",
        "# Import necessary libraries and modules\n",
        "import logging\n",
        "import os\n",
        "import json\n",
        "import mlflow\n",
        "from io import StringIO\n",
        "from mlflow.pyfunc.scoring_server import infer_and_parse_json_input, predictions_to_json\n",
        "\n",
        "# Set up Azure logging\n",
        "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
        "\n",
        "# Connect to Application Insights and set logging level to INFO\n",
        "application_insights_connection_string = 'InstrumentationKey=85de5fe8-9310-4e68-bb70-7ae940017984;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/;ApplicationId=7b4604c7-4039-4c00-b7a1-bd2e4c5a61a0'\n",
        "handler = AzureLogHandler(connection_string=application_insights_connection_string)\n",
        "logger = logging.getLogger()\n",
        "logger.addHandler(handler)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Define the init() function to load the MLflow model\n",
        "def init():\n",
        "    global model\n",
        "    global input_schema\n",
        "    # \"model\" is the path of the mlflow artifacts when the model was registered. For automl\n",
        "    # models, this is generally \"mlflow-model\".\n",
        "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"GradientBoosting_GC\")\n",
        "    model = mlflow.pyfunc.load_model(model_path)\n",
        "    input_schema = model.metadata.get_input_schema()\n",
        "\n",
        "# Define the run() function to make predictions using the loaded model\n",
        "def run(raw_data):\n",
        "    # Parse input data\n",
        "    json_data = json.loads(raw_data)\n",
        "    if \"input_data\" not in json_data.keys():\n",
        "        raise Exception(\"Request must contain a top level key named 'input_data'\")\n",
        "    \n",
        "    serving_input = json_data[\"input_data\"]\n",
        "    serving_input_str = json.dumps(serving_input)  # Convert the dictionary to a JSON string\n",
        "    data = infer_and_parse_json_input(serving_input_str, input_schema)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(data)\n",
        "\n",
        "    # Log the input data and predictions to Azure\n",
        "    logger.info(\"Data: {0}, Predictions: {1}\".format(str(data), str(predictions)))\n",
        "\n",
        "    # Convert predictions to JSON format and return\n",
        "    result = StringIO()\n",
        "    predictions_to_json(predictions, result)\n",
        "    return result.getvalue()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/gb_script.py\n"
        }
      ],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display.Image(\"Image/Image3.png\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'function' object has no attribute 'Image'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage/Image3.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'Image'"
          ]
        }
      ],
      "execution_count": 60,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765553824
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Infrastructure & Execution"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blue Deployment:\n",
        "\n",
        "* The base model that we will deploy is referred to as the \"blue\" model by convention. After creation, this endpoint will be serving 100% of the traffic with the variant tagged as the blue version (the SVM model in this case).\n",
        "\n",
        "* Once the server logic is implemented in the scoring script, we define the infrastructure we need to host and serve the model. Azure ML handles the resources needed to create the model server and attaches it to the endpoint with the name specified (note that the managed endpoint was created in the first step)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\", # Name for the deployment\n",
        "    endpoint_name=online_endpoint_name, # Name of the endpoint to deploy to\n",
        "    model=registered_model_DT, # Registered model to deploy\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\", # Environment to use for the deployment\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code='./src',\n",
        "        scoring_script='dt_script.py'# Name of the scoring script\n",
        "    ),\n",
        "    instance_type=\"Standard_E2S_v3\",\n",
        "    instance_count=1 # Number of instances to create\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 61,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765559057
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint german-credit-classifier-juvlin exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".........................................................................."
        },
        {
          "output_type": "execute_result",
          "execution_count": 62,
          "data": {
            "text/plain": "ManagedOnlineDeployment({'private_network_connection': None, 'package_model': False, 'provisioning_state': 'Succeeded', 'endpoint_name': 'german-credit-classifier-juvlin', 'type': 'Managed', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/odidp:533a1434-a3da-4be8-bff0-922142657211:b90e9270-892b-4749-9ad4-787eb739da58?api-version=2023-04-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/onlineEndpoints/german-credit-classifier-juvlin/deployments/blue', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/pinhe512611/code/Users/pinhe51261/Code', 'creation_context': <azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.SystemData object at 0x7f7ca84e31c0>, 'serialize': <msrest.serialization.Serializer object at 0x7f7ca84d47f0>, 'model': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/models/Decisiontree_GC/versions/2', 'code_configuration': {'code': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/codes/fdbaf1ec-42fb-4492-8cf5-8b7731b46dcd/versions/1'}, 'environment': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/environments/AzureML-sklearn-0.24-ubuntu18.04-py37-cpu/versions/49', 'environment_variables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AZUREML_MODEL_DIR': '/var/azureml-app/azureml-models/Decisiontree_GC/2', 'AZUREML_ENTRY_SCRIPT': 'dt_script.py', 'AML_APP_ROOT': '/var/azureml-app/src'}, 'app_insights_enabled': False, 'scale_settings': <azure.ai.ml.entities._deployment.scale_settings.DefaultScaleSettings object at 0x7f7ca84d63b0>, 'request_settings': <azure.ai.ml.entities._deployment.deployment_settings.OnlineRequestSettings object at 0x7f7ca8803ca0>, 'liveness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7f7ca84d6b60>, 'readiness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7f7ca84d6680>, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'Standard_E2S_v3', 'data_collector': None, 'egress_public_network_access': 'Enabled'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731765941464
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invoking the specified endpoint and deployment with a sample input file named \"sample-data_dt.json\". It then prints the output of the invocation."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    ml_client.online_endpoints.invoke(\n",
        "        endpoint_name=online_endpoint_name,\n",
        "        deployment_name=\"blue\",\n",
        "        request_file=\"../src_test/sample_dt.json\"\n",
        "    )\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\"[1, 1]\"\n"
        }
      ],
      "execution_count": 74,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731768064113
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Canary Deployment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An important scenario in model deployment is the need to upgrade an existing baseline model to a newer version. A recommended approach to ensure a careful transition from the existing model (\"blue\") to the new version (\"green\") is through a canary deployment. This method involves directing a controlled portion of the live traffic to the upgraded endpoint. A/B testing is then performed to determine if the upgraded version performs better than the baseline on live data. The canary deployment process begins by diverting a small percentage of live traffic (typically between 1% and 5%) to the upgraded version and gradually increasing traffic if there are no errors."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Green Deployment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the second registered model as a \"green\" variant to be attached to the managed end point."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "green_deployment = ManagedOnlineDeployment(\n",
        "    name=\"green\", # The name of the deployment\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=registered_model_GB,\n",
        "    environment=\"machine_learning_model_serving@latest\",\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code='./src',\n",
        "        scoring_script='gb_script.py'# The name of the scoring script to run for the deployment\n",
        "    ),\n",
        "    instance_type=\"Standard_E2S_v3\",\n",
        "    instance_count=1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 64,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731766094001
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_deployments.begin_create_or_update(green_deployment).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint german-credit-classifier-juvlin exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".........................................................................."
        },
        {
          "output_type": "execute_result",
          "execution_count": 65,
          "data": {
            "text/plain": "ManagedOnlineDeployment({'private_network_connection': None, 'package_model': False, 'provisioning_state': 'Succeeded', 'endpoint_name': 'german-credit-classifier-juvlin', 'type': 'Managed', 'name': 'green', 'description': None, 'tags': {}, 'properties': {'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/odidp:533a1434-a3da-4be8-bff0-922142657211:19eb8a9c-8393-423f-95eb-98cf644f34b6?api-version=2023-04-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/onlineEndpoints/german-credit-classifier-juvlin/deployments/green', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/pinhe512611/code/Users/pinhe51261/Code', 'creation_context': <azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.SystemData object at 0x7f7ca8516110>, 'serialize': <msrest.serialization.Serializer object at 0x7f7ca85165c0>, 'model': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/models/GradientBoosting_GC/versions/2', 'code_configuration': {'code': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/codes/fdbaf1ec-42fb-4492-8cf5-8b7731b46dcd/versions/1'}, 'environment': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/environments/machine_learning_model_serving/versions/3', 'environment_variables': {'AZUREML_MODEL_DIR': '/var/azureml-app/azureml-models/GradientBoosting_GC/2', 'AZUREML_ENTRY_SCRIPT': 'gb_script.py', 'AML_APP_ROOT': '/var/azureml-app/src'}, 'app_insights_enabled': False, 'scale_settings': <azure.ai.ml.entities._deployment.scale_settings.DefaultScaleSettings object at 0x7f7ca85163b0>, 'request_settings': <azure.ai.ml.entities._deployment.deployment_settings.OnlineRequestSettings object at 0x7f7ca8515240>, 'liveness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7f7ca8517f40>, 'readiness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7f7ca8517e80>, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'Standard_E2S_v3', 'data_collector': None, 'egress_public_network_access': 'Enabled'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 65,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731766475824
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invoking the specified endpoint and deployment with a sample input file named \"sample-data_gb.json\". It then prints the output of the invocation."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    ml_client.online_endpoints.invoke(\n",
        "        endpoint_name=online_endpoint_name,\n",
        "        deployment_name=\"green\",\n",
        "        request_file=\"../src_test/sample-data_gb.json\"\n",
        "    )\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\"{\\\"predictions\\\": [1, 1]}\"\n"
        }
      ],
      "execution_count": 76,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731768128635
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Safe rollout"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the green variant is tested, we can define the traffic proportions to be allocated dynamically, gradually increasing the traffic seen by the green endpoint, eventually rolling over completely."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint.traffic = {\"blue\": 99, \"green\": 1}"
      ],
      "outputs": [],
      "execution_count": 66,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731766491440
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://german-credit-classifier-juvlin.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://german-credit-classifier-juvlin.eastus2.inference.ml.azure.com/swagger.json', 'name': 'german-credit-classifier-juvlin', 'description': 'Model to predict german credit', 'tags': {}, 'properties': {'createdBy': 'Juvlin Pinheiro', 'createdAt': '2024-11-16T13:56:52.758303+0000', 'lastModifiedAt': '2024-11-16T13:56:52.758303+0000', 'azureml.onlineendpointid': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/juvlinresourcegroup/providers/microsoft.machinelearningservices/workspaces/juvlinworkspace/onlineendpoints/german-credit-classifier-juvlin', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oeidp:533a1434-a3da-4be8-bff0-922142657211:4f9d11c0-2362-4c22-b84a-16eeb583c32a?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/onlineEndpoints/german-credit-classifier-juvlin', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/pinhe512611/code/Users/pinhe51261/Code', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f7ca8516440>, 'auth_mode': 'aml_token', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f7ca85153f0>, 'traffic': {'blue': 99, 'green': 1}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 67,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731766529853
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display.Image(\"Image/Image4.png\")"
      ],
      "outputs": [],
      "execution_count": 69,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731766545640
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean up"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid costs incurred on idle endpoints during the testing phase, it is a good practise to delete end points. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731760650587
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}