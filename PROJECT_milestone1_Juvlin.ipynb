{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone 1: Advertising"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Business Context:** \n\nRetail company, \"Fashion Haven,\" operates multiple stores in different cities. The company invests in advertising campaigns to promote its latest collections through various media sources like TV, Newspaper, and Radio. They want to understand the impact of each media source on their sales revenue to optimize their advertising strategy and improve overall business performance.\n\nCurrently, Fashion Haven lacks an effective method to predict the sales revenue generated from their advertising efforts accurately. As a result, they struggle to allocate their advertising budget optimally across different media channels, leading to sub optimal returns on investment and inefficient resource allocation.\n\nTo address this business problem, Fashion Haven has collected historical data containing information on various advertising campaigns (TV, Newspaper, Radio) and their corresponding sales revenue across their different store locations. The goal is to build a robust predictive model that accurately estimates the sales revenue based on the media sources' advertising budgets, helping the company make data-driven decisions and drive business growth.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Description:\n",
        "\n",
        "The data contains the different attributes of the advertising business. The detailed data dictionary is given below.\n",
        "\n",
        "* TV: Expenditure on media resource- TV \n",
        "* Radio: Expenditure on media resource- Radio \n",
        "* NewsPaper: Expenditure on media resource- Newspaper \n",
        "* Sales: Target Column - Amount of Sales"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Connect to the Workspace **  "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credential = DefaultAzureCredential()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874338988
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"6793e723-756c-4c5d-84c0-812f1bb4c679\", # Subscription ID\n",
        "    resource_group_name=\"JuvlinResourceGroup\",              # Resource Group\n",
        "    workspace_name=\"JuvlinWorkspace\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874339293
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Upload the dataset on Blob Storage as Data Asset **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Data Asset created from File uploaded to Blob Storage\n",
        "data_asset = ml_client.data.get(\"advertising_data\", version=\"1\")\n",
        "da_path=data_asset.path\t\t\t\t\t\t\t\t\n",
        "print(da_path)\t\t"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azureml://subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace/datastores/workspaceblobstore/paths/UI/2024-11-09_202832_UTC/advertising_raw.csv/\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874339569
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Create a Compute Resource to run the Jobs **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Assign Name to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster-E2E\"\n",
        "\n",
        "# Define the Azure ML compute object with the intended parameters\n",
        "cpu_cluster = AmlCompute(\n",
        "    name=cpu_compute_target,\n",
        "    type=\"amlcompute\",                 # Azure ML Compute is the on-demand VM service\n",
        "    size=\"STANDARD_D2_V3\",             # VM Family\n",
        "    min_instances=0,                   # Minimum running nodes when there is no job running\n",
        "    max_instances=1,                   # Nodes in cluster\n",
        "    idle_time_before_scale_down=180,   # How many seconds will the node running after the job termination\n",
        "    tier=\"Dedicated\",                  # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        ")\n",
        "\n",
        "try:\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)  # Check if the compute target already exists\n",
        "    print(\n",
        "        f\"Compute Cluster {cpu_compute_target} exists, reuse it as is.\"\n",
        "    )\n",
        "except Exception:\n",
        "    print(\"Creating a new Compute Cluster...\") \n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster).result()   # Pass the object to MLClient's create_or_update method\n",
        "    print(\n",
        "    f\"AMLCompute Cluster {cpu_cluster.name} created, the compute size is {cpu_cluster.size}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Compute Cluster cpu-cluster-E2E exists, reuse it as is.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874339912
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Create a Custom Job Environment **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Name of the directory to create\n",
        "dependencies_dir = \"./env\"\n",
        "\n",
        "# Make directory, if exists don't raise an exception \n",
        "os.makedirs(dependencies_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874340061
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Create YAML File with required dependencies **\n",
        "\n",
        "-  ** 1. Create and Register the Custom Job Environment in the Workspace. **\n",
        "-  ** 2. The Environment will be packaged into a Docker Container at runtime. **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {dependencies_dir}/conda1.yaml\n",
        "\n",
        "name: sklearn-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - pip=21.2.4\n",
        "  - scikit-learn=1.0.2\n",
        "  - scipy=1.7.1\n",
        "  - pip:  \n",
        "    - mlflow==2.8.1\n",
        "    - azureml-mlflow==1.51.0\n",
        "    - azureml-inference-server-http\n",
        "    - azureml-core==1.49.0\n",
        "    - cloudpickle==1.6.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./env/conda1.yaml\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731214618379
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Create Environment for ML Tasks **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Environment Class from the azure.ai.ml.entities module\n",
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "\n",
        "# Name of the Custom Environment to create\n",
        "custom_env_name = \"Milestone1_Project_E2E\"\n",
        "\n",
        "# Create Environment object with the specified properties\n",
        "job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom Environment for ML task\",\n",
        "    conda_file=os.path.join(dependencies_dir, \"conda1.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "job_env = ml_client.environments.create_or_update(job_env)\n",
        "\n",
        "# Print information for registered environment\n",
        "print(\n",
        "    f\"Environment {job_env.name} registered to workspace, the environment version is {job_env.version}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment Milestone1_Project_E2E registered to workspace, the environment version is 14\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874341344
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Exploratory Data Analysis **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required Libraries\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "df = pd.read_csv(da_path)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874353227
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse Features to the correct datatypes\n",
        "df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 200 entries, 0 to 199\nData columns (total 4 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   TV         200 non-null    float64\n 1   Radio      200 non-null    float64\n 2   Newspaper  200 non-null    float64\n 3   Sales      200 non-null    float64\ndtypes: float64(4)\nmemory usage: 6.4 KB\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874353403
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Table Summary\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "               TV       Radio   Newspaper       Sales\ncount  200.000000  200.000000  200.000000  200.000000\nmean   147.042500   23.264000   30.554000   14.022500\nstd     85.854236   14.846809   21.778621    5.217457\nmin      0.700000    0.000000    0.300000    1.600000\n25%     74.375000    9.975000   12.750000   10.375000\n50%    149.750000   22.900000   25.750000   12.900000\n75%    218.825000   36.525000   45.100000   17.400000\nmax    296.400000   49.600000  114.000000   27.000000",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>Radio</th>\n      <th>Newspaper</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>200.000000</td>\n      <td>200.000000</td>\n      <td>200.000000</td>\n      <td>200.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>147.042500</td>\n      <td>23.264000</td>\n      <td>30.554000</td>\n      <td>14.022500</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>85.854236</td>\n      <td>14.846809</td>\n      <td>21.778621</td>\n      <td>5.217457</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.700000</td>\n      <td>0.000000</td>\n      <td>0.300000</td>\n      <td>1.600000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>74.375000</td>\n      <td>9.975000</td>\n      <td>12.750000</td>\n      <td>10.375000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>149.750000</td>\n      <td>22.900000</td>\n      <td>25.750000</td>\n      <td>12.900000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>218.825000</td>\n      <td>36.525000</td>\n      <td>45.100000</td>\n      <td>17.400000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>296.400000</td>\n      <td>49.600000</td>\n      <td>114.000000</td>\n      <td>27.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874353576
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 record\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "      TV  Radio  Newspaper  Sales\n0  230.1   37.8       69.2   22.1\n1   44.5   39.3       45.1   10.4\n2   17.2   45.9       69.3    9.3\n3  151.5   41.3       58.5   18.5\n4  180.8   10.8       58.4   12.9",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>Radio</th>\n      <th>Newspaper</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>230.1</td>\n      <td>37.8</td>\n      <td>69.2</td>\n      <td>22.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44.5</td>\n      <td>39.3</td>\n      <td>45.1</td>\n      <td>10.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17.2</td>\n      <td>45.9</td>\n      <td>69.3</td>\n      <td>9.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>151.5</td>\n      <td>41.3</td>\n      <td>58.5</td>\n      <td>18.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>180.8</td>\n      <td>10.8</td>\n      <td>58.4</td>\n      <td>12.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874353761
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the last 5 record\n",
        "df.tail()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "        TV  Radio  Newspaper  Sales\n195   38.2    3.7       13.8    7.6\n196   94.2    4.9        8.1    9.7\n197  177.0    9.3        6.4   12.8\n198  283.6   42.0       66.2   25.5\n199  232.1    8.6        8.7   13.4",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>Radio</th>\n      <th>Newspaper</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>195</th>\n      <td>38.2</td>\n      <td>3.7</td>\n      <td>13.8</td>\n      <td>7.6</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>94.2</td>\n      <td>4.9</td>\n      <td>8.1</td>\n      <td>9.7</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>177.0</td>\n      <td>9.3</td>\n      <td>6.4</td>\n      <td>12.8</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>283.6</td>\n      <td>42.0</td>\n      <td>66.2</td>\n      <td>25.5</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>232.1</td>\n      <td>8.6</td>\n      <td>8.7</td>\n      <td>13.4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874353998
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "df.isnull().sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "TV           0\nRadio        0\nNewspaper    0\nSales        0\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874354176
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Conclusion: There are no missing or null values **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for all duplicate rows\n",
        "df[df.duplicated()]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "Empty DataFrame\nColumns: [TV, Radio, Newspaper, Sales]\nIndex: []",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>Radio</th>\n      <th>Newspaper</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874354361
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Conclusion: There are no duplicate records **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA Conclusion: Data is clean and no additional preprocessing is needed ###"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Create a Training Script to perform the Training Job **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Directory to store Training Script file\n",
        "import os\n",
        "\n",
        "src_dir = \"./src\"\n",
        "os.makedirs(src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874354660
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/milestone1_training.py\n",
        "\n",
        "# Import required Libraries\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# Create an argument parser for input arguments from command line\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument('--criterion', type=str, default='mse', help='measure the quality of a split')\n",
        "    parser.add_argument('--max-depth', type=int, default=None, help='The maximum depth of the tree.')\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # Enable AutoLogging\n",
        "    # mlflow.sklearn.autolog()\n",
        "\n",
        "    # Print Input Arguments\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    # Load Input Data\n",
        "    print(\"input data:\", args.data)\n",
        "    df = pd.read_csv(args.data)\n",
        "\n",
        "    # Log input hyperparameters\n",
        "    mlflow.log_param('Criterion', str(args.criterion))\n",
        "    mlflow.log_param('Max depth', str(args.max_depth))\n",
        "\n",
        "    # Split data into features (X) and target (y)\n",
        "    X = df[['TV', 'Radio', 'Newspaper']]\n",
        "    y = df['Sales']\n",
        "    \n",
        "    # Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=args.test_train_ratio, random_state=42)\n",
        "    \n",
        "    # Initialize and Train a Decision Tree Regressor\n",
        "\n",
        "    tree_model = DecisionTreeRegressor(criterion=args.criterion, max_depth=args.max_depth, random_state=42)\n",
        "    tree_model = tree_model.fit(X_train, y_train)\n",
        "    tree_predictions = tree_model.predict(X_test)\n",
        "\n",
        "    # Compute and Log Model for MSE metric\n",
        "    mse = mean_squared_error(y_test, tree_predictions)\n",
        "    print(f\"Mean Squared Error on test set: {mse}\")\n",
        "    mlflow.log_metric('Mean Squared Error', float(mse))\n",
        "\n",
        "    # Set Name for the Registered Model\n",
        "    registered_model_name=\"milestone1_model\"\n",
        "\n",
        "    # Register Model to the Workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=tree_model,\n",
        "        registered_model_name=registered_model_name,\n",
        "        artifact_path=registered_model_name\n",
        "    )\n",
        "\n",
        "    # Save Model to a File\n",
        "    print(\"Saving the model via MLFlow\")\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=tree_model,\n",
        "        path=os.path.join(registered_model_name, 'trained_model'),\n",
        "    )\n",
        "   \n",
        "    # End MLflow tracking\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/milestone1_training.py\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731214681568
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Configure the Training Job **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required Modules\n",
        "\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "# Define a new AML job using the Command function\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",           \n",
        "            path=da_path,                      # Path to the input data file        \n",
        "        ),\n",
        "        test_train_ratio=0.3,                  # Ratio of the data to be used for testing\n",
        "        criterion=\"mse\",                       # Criterion used to measure the quality of a split\n",
        "        max_depth=2,                           # Maximum depth of the Decision Tree\n",
        "    ),\n",
        "    \n",
        "    code=\"./src/\",                             # Specify Directory containing the code to be run in the job\n",
        " \n",
        "    # Specify command to run in the job, including the input data and parameters as command line arguments\n",
        "    command=\"python milestone1_training.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --criterion ${{inputs.criterion}} --max-depth ${{inputs.max_depth}}\",\n",
        " \n",
        "    environment=\"Milestone1_Project_E2E@latest\",     # Specify environment or job\n",
        "    compute=\"cpu-cluster-E2E\",                       # Specify compute target for job\n",
        "    experiment_name=\"train_milestone1_prediction\",   # Specify experiment name for job \n",
        "    display_name=\"milestone1_prediction\",            # Specify display name for job\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874354951
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Run the Training Job **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new Job or update using ml_client.create_or_update\n",
        "training_job = ml_client.create_or_update(job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874356691
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wait for the job to complete by streaming logs\n",
        "ml_client.jobs.stream(training_job.name)\n",
        "\n",
        "# Proceed with the next steps after the job is complete\n",
        "print(\"Job has completed. Proceeding to the next step.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: sharp_fox_vrys9pdsd5\nWeb View: https://ml.azure.com/runs/sharp_fox_vrys9pdsd5?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\nExecution Summary\n=================\nRunId: sharp_fox_vrys9pdsd5\nWeb View: https://ml.azure.com/runs/sharp_fox_vrys9pdsd5?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\nJob has completed. Proceeding to the next step.\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874883766
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Define the parameter space for Hyperparameter Tuning **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.sweep import Choice\n",
        "\n",
        "# Reuse the command_job created \n",
        "job_for_sweep = job(\n",
        "    criterion=Choice(values=[\"mse\"]),\n",
        "    max_depth=Choice(values=[2, 3, 4, 5]),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874883955
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Configure the Sweep Job for Tuning **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ** compute ** - specifies the compute target where the sweep job will run.\n",
        "- ** sampling_algorithm ** - specifies the search algorithm to use for hyperparameter tuning.\n",
        "- ** primary_metric ** - specifies the metric to optimize during hyperparameter tuning.\n",
        "- ** goal ** - specifies whether to maximize or minimize the primary metric.\n",
        "- ** max_total_trials ** - specifies the maximum number of trials to run during hyperparameter tuning.\n",
        "- ** max_concurrent_trials ** - specifies the maximum number of trials to run concurrently during hyperparameter tuning."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Sweep Job\n",
        "sweep_job = job_for_sweep.sweep(\n",
        "    compute=\"cpu-cluster-E2E\",\n",
        "    sampling_algorithm=\"random\",\n",
        "    primary_metric=\"Mean Squared Error\",\n",
        "    goal=\"Minimize\",\n",
        "    max_total_trials=4,\n",
        "    max_concurrent_trials=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874884105
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Run the Sweep Job **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create or update the Sweep Job\n",
        "returned_sweep_job = ml_client.create_or_update(sweep_job) "
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731874886280
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stream the output and wait until the Job is finished\n",
        "ml_client.jobs.stream(returned_sweep_job.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: jovial_rabbit_5cqw967x3w\nWeb View: https://ml.azure.com/runs/jovial_rabbit_5cqw967x3w?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\nStreaming azureml-logs/hyperdrive.txt\n=====================================\n\n[2024-11-17T20:21:27.2775093Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-17T20:21:27.5689428Z][SCHEDULER][INFO]Scheduling job, id='jovial_rabbit_5cqw967x3w_0' \n[2024-11-17T20:21:28.4427759Z][SCHEDULER][INFO]Successfully scheduled a job. Id='jovial_rabbit_5cqw967x3w_0' \n[2024-11-17T20:22:28.9364707Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-17T20:22:29.0853338Z][SCHEDULER][INFO]Scheduling job, id='jovial_rabbit_5cqw967x3w_1' \n[2024-11-17T20:22:29.3427986Z][SCHEDULER][INFO]Successfully scheduled a job. Id='jovial_rabbit_5cqw967x3w_1' \n[2024-11-17T20:23:30.4353662Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-17T20:23:30.7222855Z][SCHEDULER][INFO]Scheduling job, id='jovial_rabbit_5cqw967x3w_2' \n[2024-11-17T20:23:31.0254978Z][SCHEDULER][INFO]Successfully scheduled a job. Id='jovial_rabbit_5cqw967x3w_2' \n[2024-11-17T20:24:32.0462332Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-17T20:24:32.1965719Z][SCHEDULER][INFO]Scheduling job, id='jovial_rabbit_5cqw967x3w_3' \n[2024-11-17T20:24:32.5821275Z][SCHEDULER][INFO]Successfully scheduled a job. Id='jovial_rabbit_5cqw967x3w_3' \n[2024-11-17T20:25:02.2822143Z][GENERATOR][DEBUG]Setting all jobs generated as True, reason : Max number of jobs reached \n[2024-11-17T20:25:59.6091710Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n\nExecution Summary\n=================\nRunId: jovial_rabbit_5cqw967x3w\nWeb View: https://ml.azure.com/runs/jovial_rabbit_5cqw967x3w?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace\n\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875180735
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Refresh the latest status of the Job after Streaming\n",
        "returned_sweep_job = ml_client.jobs.get(name=returned_sweep_job.name)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875181078
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Extract the run that gave Best Modeling results **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the Best Model\n",
        "from azure.ai.ml.entities import Model\n",
        "\n",
        "if returned_sweep_job.status == \"Completed\":\n",
        "\n",
        "    # Get the run with the best result\n",
        "    best_run = returned_sweep_job.properties[\"best_child_run_id\"]\n",
        "\n",
        "    # Get the Model from that run\n",
        "    model = Model(\n",
        "        # Stores the Best Model as \"milestone1_best_model\"\n",
        "        path=\"azureml://jobs/{}/outputs/artifacts/paths/milestone1_model/\".format(\n",
        "            best_run\n",
        "        ),\n",
        "        name=\"milestone1_best_model\",\n",
        "        description=\"Model created from Advertising for Milestone1 Project\",\n",
        "        type=\"custom_model\",\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print(\n",
        "        \"Sweep job status: {}. Please wait until it completes\".format(\n",
        "            returned_sweep_job.status\n",
        "        )\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875181251
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best Model: {model.name}\")\n",
        "print(f\"Best Model Path: {model.path}\")\n",
        "print(f\"Best Model Type: {model.type}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Best Model: milestone1_best_model\nBest Model Path: azureml://jobs/jovial_rabbit_5cqw967x3w_2/outputs/artifacts/paths/milestone1_model/\nBest Model Type: custom_model\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875181415
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Register the Best Model **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the Best Model\n",
        "registered_model = ml_client.models.create_or_update(model=model)\n",
        "print(f\"Best Model: {registered_model.name}\")\n",
        "print(f\"Best Model Path: {registered_model.path}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Best Model: milestone1_best_model\nBest Model Path: azureml://subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.jovial_rabbit_5cqw967x3w_2/milestone1_model\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875182691
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Configure an Endpoint **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required Libraries\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "from azure.ai.ml.constants import AssetTypes"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875182869
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a unique Endpoint Name\n",
        "endpoint_suffix = \"juvlin\"\n",
        "endpoint_name = \"milestone1-endpoint-\" + endpoint_suffix\n",
        "print(f\"Endpoint name: {endpoint_name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint name: milestone1-endpoint-juvlin\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875183013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the Endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name,   # Unique Endpoint Name within Deployment\n",
        "    description=\"An online endpoint serving an MLflow model, for Milestone1 Advertising Prediction task\",\n",
        "                          # A string describing the purpose of the endpoint\n",
        "    auth_mode=\"key\",      # Authentication mode for endpoint - API key\n",
        "    tags={\"foo\": \"bar\"},  # Dictionary of key-value pairs to tag the Endpoint\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875183156
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Create an Endpoint **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Endpoint\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://milestone1-endpoint-juvlin.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://milestone1-endpoint-juvlin.eastus2.inference.ml.azure.com/swagger.json', 'name': 'milestone1-endpoint-juvlin', 'description': 'An online endpoint serving an MLflow model, for Milestone1 Advertising Prediction task', 'tags': {'foo': 'bar'}, 'properties': {'createdBy': 'Juvlin Pinheiro', 'createdAt': '2024-11-17T20:26:24.142924+0000', 'lastModifiedAt': '2024-11-17T20:26:24.142924+0000', 'azureml.onlineendpointid': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/juvlinresourcegroup/providers/microsoft.machinelearningservices/workspaces/juvlinworkspace/onlineendpoints/milestone1-endpoint-juvlin', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oeidp:533a1434-a3da-4be8-bff0-922142657211:d9a05d9c-284e-4194-92a2-412ef418bb21?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/onlineEndpoints/milestone1-endpoint-juvlin', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/pinhe512611/code/Users/pinhe51261/Code', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7feb80fa9ea0>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7feb80fa9d20>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875245142
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"milestone1_best_model\"\n",
        "\n",
        "model = Model(\n",
        "    name=model_name,\n",
        "    #The name of the MLflow model.\n",
        "    path=\"milestone1_best_model/milestone1_model\",\n",
        "    #Path to the root directory of the model.\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    #The type of the model asset(MLflow model).\n",
        "    description=\"MLflow model for the advertising regression problem\",\n",
        "    #The purpose of the model.\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875245318
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Create a Deployment Script to perform Model Deployment **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/score.py\n",
        "\n",
        "# Import necessary libraries and modules\n",
        "import logging\n",
        "import os\n",
        "import json\n",
        "import mlflow\n",
        "from io import StringIO\n",
        "from mlflow.pyfunc.scoring_server import infer_and_parse_json_input, predictions_to_json\n",
        "\n",
        "######################LOGGER#####################\n",
        "# Set up Azure logging\n",
        "import logging\n",
        "from logging import Logger\n",
        "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
        "\n",
        "# Connect to Application Insights and set logging level to INFO\n",
        "application_insights_connection_string= 'InstrumentationKey=7854c827-606d-4b69-b4e5-9933d009107d;IngestionEndpoint=https://eastus2-3.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus2.livediagnostics.monitor.azure.com/;ApplicationId=e9fab746-46e7-40c3-b8d0-9735b787df2d'\n",
        "handler = AzureLogHandler(\n",
        "connection_string=application_insights_connection_string)\n",
        "logger = logging.getLogger()\n",
        "logger.addHandler(handler)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "####################################################\n",
        "\n",
        "# Define the init() function to load the MLflow model\n",
        "def init():\n",
        "    global model\n",
        "    global input_schema\n",
        "    # \"model\" is the path of the mlflow artifacts when the model was registered. For automl\n",
        "    # models, this is generally \"mlflow-model\".\n",
        "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"milestone1_model\")\n",
        "    model = mlflow.pyfunc.load_model(model_path)\n",
        "    input_schema = model.metadata.get_input_schema()\n",
        "\n",
        "# Define the run() function to make predictions using the loaded model\n",
        "def run(raw_data):\n",
        "    # Parse input data\n",
        "    json_data = json.loads(raw_data)\n",
        "    if \"input_data\" not in json_data.keys():\n",
        "        raise Exception(\"Request must contain a top level key named 'input_data'\")\n",
        "    serving_input = json.dumps(json_data[\"input_data\"])\n",
        "    data = infer_and_parse_json_input(serving_input, input_schema)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(data)\n",
        "\n",
        "    # Log the input data and predictions to Azure\n",
        "    logger.info(\"Data:{0},Predictions:{1}\".format(str(data),str(predictions)))\n",
        "\n",
        "    # Convert predictions to JSON format and return\n",
        "    result = StringIO()\n",
        "    predictions_to_json(predictions, result)\n",
        "    return result.getvalue()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/score.py\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=endpoint_name,                  # Use the previously generated endpoint name\n",
        "    model=registered_model,                       # Use the registered model\n",
        "    environment=\"Milestone1_Project_E2E@latest\",  # Use the latest environment\"\n",
        "    # Use the code in the \"./src\" directory and the \"score.py\" script\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src\", scoring_script=\"score.py\"\n",
        "    ),\n",
        "    instance_type=\"Standard_E2s_v3\",              # Use a single instance of type \"Standard_E2s_v3\"\n",
        "    instance_count=1,\n",
        "    app_insights_enabled=True,                    # Enable Application Insights for the deployment\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875245690
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"Model Path: {model_path}\")\n",
        "# print(f\"Model Name: {model.name}\")"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875245878
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy the Model to Endpoint\n",
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint milestone1-endpoint-juvlin exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".................................................................."
        },
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "ManagedOnlineDeployment({'private_network_connection': None, 'package_model': False, 'provisioning_state': 'Succeeded', 'endpoint_name': 'milestone1-endpoint-juvlin', 'type': 'Managed', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/odidp:533a1434-a3da-4be8-bff0-922142657211:c539ac1d-dec0-4e75-ac8d-3bb6d528b013?api-version=2023-04-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/onlineEndpoints/milestone1-endpoint-juvlin/deployments/blue', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/pinhe512611/code/Users/pinhe51261/Code', 'creation_context': <azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.SystemData object at 0x7feb80f663b0>, 'serialize': <msrest.serialization.Serializer object at 0x7feb80f27e80>, 'model': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/models/milestone1_best_model/versions/2', 'code_configuration': {'code': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/codes/92990e24-1b53-4f9f-90a0-fc2be7ebbea5/versions/1'}, 'environment': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/environments/Milestone1_Project_E2E/versions/14', 'environment_variables': {'AML_APP_INSIGHTS_KEY': '7854c827-606d-4b69-b4e5-9933d009107d', 'AML_APP_INSIGHTS_ENDPOINT': 'https://dc.services.visualstudio.com/v2/track', 'AML_APP_INSIGHTS_ENABLED': 'true', 'AZUREML_MODEL_DIR': '/var/azureml-app/azureml-models/milestone1_best_model/2', 'AZUREML_ENTRY_SCRIPT': 'score.py', 'AML_APP_ROOT': '/var/azureml-app/src'}, 'app_insights_enabled': True, 'scale_settings': <azure.ai.ml.entities._deployment.scale_settings.DefaultScaleSettings object at 0x7feb80f26ef0>, 'request_settings': <azure.ai.ml.entities._deployment.deployment_settings.OnlineRequestSettings object at 0x7feb80f66410>, 'liveness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7feb80f27eb0>, 'readiness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7feb80f26f50>, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'Standard_E2s_v3', 'data_collector': None, 'egress_public_network_access': 'Enabled'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875585310
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the endpoint and deployment names to verify they are correctly assigned\n",
        "print(\"Endpoint Name:\", endpoint_name)\n",
        "print(\"Deployment Name:\", \"blue\")\n",
        "# print(\"Endpoint invocation response:\", response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint Name: milestone1-endpoint-juvlin\nDeployment Name: blue\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875585459
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect Logs for Specific Errors:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ml_client.online_deployments.get_logs(name=\"blue\", endpoint_name=endpoint_name)"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875585608
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ** Delete the Endpoint **\n",
        "\n",
        "**Important!** An Endpoint is a LIVE node which is always running, ready to process & predict to give you output. So unless you are making real-time predictions on streaming data, delete your endpoints after use"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete Endpoint\n",
        "# ml_client.online_endpoints.begin_delete(name=endpoint_name)"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731875585761
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}