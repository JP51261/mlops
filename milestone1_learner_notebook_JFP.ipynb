{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone 1: Advertising"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Business Context:** \n\nRetail company, \"Fashion Haven,\" operates multiple stores in different cities. The company invests in advertising campaigns to promote its latest collections through various media sources like TV, Newspaper, and Radio. They want to understand the impact of each media source on their sales revenue to optimize their advertising strategy and improve overall business performance.\n\nCurrently, Fashion Haven lacks an effective method to predict the sales revenue generated from their advertising efforts accurately. As a result, they struggle to allocate their advertising budget optimally across different media channels, leading to sub optimal returns on investment and inefficient resource allocation.\n\nTo address this business problem, Fashion Haven has collected historical data containing information on various advertising campaigns (TV, Newspaper, Radio) and their corresponding sales revenue across their different store locations. The goal is to build a robust predictive model that accurately estimates the sales revenue based on the media sources' advertising budgets, helping the company make data-driven decisions and drive business growth.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Description:\n",
        "\n",
        "The data contains the different attributes of the advertising business. The detailed data dictionary is given below.\n",
        "\n",
        "* TV: Expenditure on media resource- TV \n",
        "* Radio: Expenditure on media resource- Radio \n",
        "* NewsPaper: Expenditure on media resource- Newspaper \n",
        "* Sales: Target Column - Amount of Sales"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to the Workspce  "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credential = DefaultAzureCredential()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731040632903
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"6793e723-756c-4c5d-84c0-812f1bb4c679\", #Provide your subscription ID as shown in the above screenshot\n",
        "    resource_group_name=\"JuvlinResourceGroup\", #Provide your Resource Group as shown in the above screenshot\n",
        "    workspace_name=\"JuvlinWorkspace\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731040633177
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Compute Resource to run the job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster-E2E\"\n",
        "\n",
        "# Let's define the Azure ML compute object with the intended parameters\n",
        "cpu_cluster = AmlCompute(\n",
        "    name=cpu_compute_target,\n",
        "    # Azure ML Compute is the on-demand VM service\n",
        "    type=\"amlcompute\",\n",
        "    # VM Family\n",
        "    size=\"STANDARD_D2_V3\",\n",
        "    # Minimum running nodes when there is no job running\n",
        "    min_instances=0,\n",
        "    # Nodes in cluster\n",
        "    max_instances=1,\n",
        "    # How many seconds will the node running after the job termination\n",
        "    idle_time_before_scale_down=180,\n",
        "    # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "    tier=\"Dedicated\",\n",
        ")\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster).result()\n",
        "    print(\n",
        "    f\"AMLCompute with name {cpu_cluster.name} is created, the compute size is {cpu_cluster.size}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You already have a cluster named cpu-cluster-E2E, we'll reuse it as is.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731040633823
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Custom Job Environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "## Set the name of the directory we want to create\n",
        "dependencies_dir = \"./env\"\n",
        "\n",
        "# # The os.makedirs() function creates a directory\n",
        "# exist_ok=True means that the function will not raise an exception if the directory already exists\n",
        "os.makedirs(dependencies_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731040633920
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create YAML File to create and Register the Custom Job Environment i the Workspace.\n",
        "The Environment will be packaged into a Docker Container at runtime."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {dependencies_dir}/conda1.yaml\n",
        "name: sklearn-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - pip=21.2.4\n",
        "  - scikit-learn=1.0.2\n",
        "  - scipy=1.7.1\n",
        "  - pip:  \n",
        "      - mlflow==2.8.1\n",
        "      - azureml-mlflow==1.51.0\n",
        "      - azureml-inference-server-http\n",
        "      - azureml-core==1.49.0\n",
        "      - cloudpickle==1.6.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./env/conda1.yaml\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the dataset on Blob Storage as Data Asset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Environment class from the azure.ai.ml.entities module\n",
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "\n",
        "# Set the name of the custom environment we want to create\n",
        "custom_env_name = \"Milestone1_JFP_E2E\"\n",
        "\n",
        "# Create an Environment object with the specified properties\n",
        "job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for machine learning task\",\n",
        "    conda_file=os.path.join(dependencies_dir, \"conda1.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "job_env = ml_client.environments.create_or_update(job_env)\n",
        "\n",
        "# Print out some information about the registered environment\n",
        "print(\n",
        "    f\"Environment with name {job_env.name} is registered to workspace, the environment version is {job_env.version}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment with name Milestone1_JFP_E2E is registered to workspace, the environment version is 14\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731040635144
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a processing script to perform the data preprocessing job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To use the training script, first create a directory where you will store the file.\n",
        "import os\n",
        "\n",
        "src_dir = \"./src\"\n",
        "os.makedirs(src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731040635242
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/milestone1_jfp.py\n",
        "\n",
        "# importing necessary libraries\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "##### from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# create an argument parser to take input arguments from command line\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument('--criterion', type=str, default='mse',\n",
        "                        help='The function to measure the quality of a split')\n",
        "    parser.add_argument('--max-depth', type=int, default=None,\n",
        "                        help='The maximum depth of the tree. If None, then nodes are expanded until all the leaves contain less than min_samples_split samples.')\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # enable autologging\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    # print input arguments\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
        "\n",
        "    # load input data\n",
        "    print(\"input data:\", args.data)\n",
        "    df = pd.read_csv(args.data)\n",
        "\n",
        "    # log input hyperparameters\n",
        "\n",
        "    mlflow.log_param('Criterion', str(args.criterion))\n",
        "    mlflow.log_param('Max depth', str(args.max_depth))\n",
        "\n",
        "    # # split the data into training and testing sets\n",
        "    # train_df, test_df = train_test_split(\n",
        "    #     df,\n",
        "    #     test_size=args.test_train_ratio,\n",
        "    # )\n",
        "\n",
        "\n",
        "    ##### training a decision tree classifier\n",
        "    # training a decision tree regressor\n",
        "\n",
        "\n",
        "    # # Extracting the label column\n",
        "    # y_train = train_df.pop(\"Sales\")\n",
        "\n",
        "    # # convert the dataframe values to array\n",
        "    # X_train = train_df.values\n",
        "\n",
        "    # # Extracting the label column\n",
        "    # y_test = test_df.pop(\"Sales\")\n",
        "\n",
        "    # # convert the dataframe values to array\n",
        "    # X_test = test_df.values\n",
        "\n",
        "\n",
        "    # Split data into features (X) and target (y)\n",
        "    X = df[['TV', 'Radio', 'Newspaper']]\n",
        "    y = df['Sales']\n",
        "    \n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=args.test_train_ratio, random_state=42)\n",
        "    \n",
        "\n",
        "\n",
        "    ##### initialize and train a decision tree classifier\n",
        "    # initialize and train a decision tree regressor\n",
        "\n",
        "    tree_model = DecisionTreeRegressor(criterion=args.criterion, max_depth=args.max_depth, random_state=42)\n",
        "    tree_model = tree_model.fit(X_train, y_train)\n",
        "    tree_predictions = tree_model.predict(X_test)\n",
        "\n",
        "# Comment out Accuracy ????????????????\n",
        "    # # compute and log model accuracy\n",
        "    # accuracy = tree_model.score(X_test, y_test)\n",
        "    # print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(accuracy))\n",
        "    # mlflow.log_metric('Accuracy', float(accuracy))\n",
        "\n",
        "    # compute and log model mse\n",
        "    mse = mean_squared_error(y_test, tree_predictions)\n",
        "    print(f\"Mean Squared Error on test set: {mse}\")\n",
        "    mlflow.log_metric('Mean Squared Error', float(mse))\n",
        "\n",
        "    # creating a confusion matrix\n",
        "    # cm = confusion_matrix(y_test, tree_predictions)\n",
        "    # print(cm)\n",
        "\n",
        "    # set the name for the registered model\n",
        "    registered_model_name=\"advertising_decisiontree_model\"\n",
        "\n",
        "    ##########################\n",
        "    #<save and register model>\n",
        "    ##########################\n",
        "\n",
        "    # Registering the model to the workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=tree_model,\n",
        "        registered_model_name=registered_model_name,\n",
        "        artifact_path=registered_model_name\n",
        "    )\n",
        "\n",
        "    # # Saving the model to a file\n",
        "    print(\"Saving the model via MLFlow\")\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=tree_model,\n",
        "        path=os.path.join(registered_model_name, 'trained_model'),\n",
        "    )\n",
        "    ###########################\n",
        "    #</save and register model>\n",
        "    ###########################\n",
        "   \n",
        "    # end MLflow tracking\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/milestone1_jfp.py\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure the processing job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "# Define a new AML job using the `command` function\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"./data/advertising_raw.csv\", # The path to the input data file\n",
        "            # path=\"/data/advertising_raw.csv\", # The path to the input data file\n",
        "        ),\n",
        "        test_train_ratio=0.3,       # The ratio of the data to be used for testing\n",
        "        criterion=\"mse\",  # The criterion used to measure the quality of a split\n",
        "        max_depth=2,                # The maximum depth of the decision tree\n",
        "    ),\n",
        "    # Specify the directory containing the code to be run in the job\n",
        "    code=\"./src/\",\n",
        "    # Specify the command to be run in the job, including the input data and parameters as command line arguments\n",
        "    command=\"python milestone1_jfp.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --criterion ${{inputs.criterion}} --max-depth ${{inputs.max_depth}}\",\n",
        "    # Specify the environment to be used for the job\n",
        "    environment=\"Milestone1_JFP_E2E@latest\",\n",
        "    # Specify the compute target to be used for the job\n",
        "    compute=\"cpu-cluster-E2E\",\n",
        "    # Specify the name of the experiment for the job\n",
        "    experiment_name=\"train_decision_tree_advertising_prediction\",\n",
        "     # Specify the display name for the job\n",
        "    display_name=\"decision_tree_advertising_prediction\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731040635423
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the processing job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ml_client.create_or_update will create a new job if it does not exist or update the existing job if it does\n",
        "ml_client.create_or_update(job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\u001b[32mUploading src (0.01 MBs): 100%|██████████| 9961/9961 [00:00<00:00, 296449.11it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "Command({'parameters': {}, 'init': False, 'name': 'amiable_spinach_61qj5bkgsb', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'cpu-cluster-E2E', 'ContentSnapshotId': 'ea5a4900-6c19-44af-95d9-f62116fb0383'}, 'print_as_yaml': False, 'id': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/jobs/amiable_spinach_61qj5bkgsb', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/pinhe512611/code/Users/pinhe51261/Code', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd6bc2f7c10>, 'serialize': <msrest.serialization.Serializer object at 0x7fd6bc333d60>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': 'decision_tree_advertising_prediction', 'experiment_name': 'train_decision_tree_advertising_prediction', 'compute': 'cpu-cluster-E2E', 'services': {'Tracking': {'endpoint': 'azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/amiable_spinach_61qj5bkgsb?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace&tid=99ce5d02-76a7-4357-a30e-e4c19d65ba5f', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/d76b5403a3179fcd4ea0e1d4ebd5e602/advertising_raw.csv', 'mode': 'ro_mount'}, 'test_train_ratio': '0.3', 'criterion': 'mse', 'max_depth': '2'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.amiable_spinach_61qj5bkgsb', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fd6bc333d00>, 'test_train_ratio': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fd6bc333d90>, 'criterion': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fd6bc333c40>, 'max_depth': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fd6bc333d30>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fd6bc333fd0>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'amiable_spinach_61qj5bkgsb', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/pinhe512611/code/Users/pinhe51261/Code', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd6bc2f7c10>, 'serialize': <msrest.serialization.Serializer object at 0x7fd6bc333eb0>, 'command': 'python milestone1_jfp.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --criterion ${{inputs.criterion}} --max-depth ${{inputs.max_depth}}', 'code': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/codes/cb9c9636-fe04-4032-aa18-6c04c7a27644/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace/environments/Milestone1_JFP_E2E/versions/14', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'decision_tree_advertising_prediction', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/d76b5403a3179fcd4ea0e1d4ebd5e602/advertising_raw.csv', 'mode': 'ro_mount'}, 'test_train_ratio': {'type': 'string', 'default': '0.3'}, 'criterion': {'type': 'string', 'default': 'mse'}, 'max_depth': {'type': 'string', 'default': '2'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.amiable_spinach_61qj5bkgsb', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourceGroups/JuvlinResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/JuvlinWorkspace?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/amiable_spinach_61qj5bkgsb?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace&tid=99ce5d02-76a7-4357-a30e-e4c19d65ba5f', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd6bc2f7c10>}, 'instance_id': 'd8f5ccee-d231-4c94-8fa9-6715831d5475', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'Milestone1_JFP_E2E:14', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>train_decision_tree_advertising_prediction</td><td>amiable_spinach_61qj5bkgsb</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/amiable_spinach_61qj5bkgsb?wsid=/subscriptions/6793e723-756c-4c5d-84c0-812f1bb4c679/resourcegroups/JuvlinResourceGroup/workspaces/JuvlinWorkspace&amp;tid=99ce5d02-76a7-4357-a30e-e4c19d65ba5f\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731040640355
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a training script to perform the training job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure the training job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the training job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the parameter space for hyperparameter tuning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure the sweep job for tuning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the sweep job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract the run that gave best modeling results"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register the best model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure an Endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an Endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a deployment script to perform model deployment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure the deployment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Delete the Endpoint\n",
        "\n",
        "**Important!** An Endpoint is a LIVE node which is always running, ready to process & predict to give you output. So unless you are making real-time predictions on streaming data, delete your endpoints after use"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}